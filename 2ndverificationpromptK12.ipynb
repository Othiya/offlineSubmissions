{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":86200,"databundleVersionId":9773555,"sourceType":"competition"},{"sourceId":8218776,"sourceType":"datasetVersion","datasetId":4871830},{"sourceId":8300737,"sourceType":"datasetVersion","datasetId":4746046},{"sourceId":9667770,"sourceType":"datasetVersion","datasetId":5907319},{"sourceId":9701197,"sourceType":"datasetVersion","datasetId":5932432}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"papermill":{"default_parameters":{},"duration":25012.51921,"end_time":"2024-10-27T15:39:56.354261","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-10-27T08:43:03.835051","version":"2.6.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"0099c4658fa94e2da1dc62a429529f66":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02b5d1da86394f509aead940e2be66e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c448a8f1cd284e449bc1dab26ca05fa5","placeholder":"​","style":"IPY_MODEL_33c46db97bcd474899c48aa7c11d7fff","value":"special_tokens_map.json: 100%"}},"045ac1de256e4ef18b98aa590fd036cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27835c8e033645eba70bab60e20114a6","placeholder":"​","style":"IPY_MODEL_a4a371b9284b47799534f7dc19872e3e","value":" 1.23k/1.23k [00:00&lt;00:00, 99.3kB/s]"}},"046a6e230692409cbe3a7b4b7c04a6ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bb4ca1e071d340369240edf48708e0b7","max":716,"min":0,"orientation":"horizontal","style":"IPY_MODEL_45022d2ad7f64df1bda26f65ce84f6a7","value":716}},"064265e47535450697afb5af5413c286":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4095eb26e4cf4a5da3de4ec1d58e5b51","placeholder":"​","style":"IPY_MODEL_bd8107edfad449649cc83cf813ac3930","value":" 4.99G/4.99G [01:58&lt;00:00, 42.9MB/s]"}},"0a693361f4574cf08c81bf1fe3a63396":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e753cbe825fe420aa44843f77241c7ab","placeholder":"​","style":"IPY_MODEL_ac4dd32d174e4ceda4bc0938d535a26a","value":"model-00002-of-00003.safetensors: 100%"}},"0c022859280a40d8b10d147c3f8c9009":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4956ed1ffd314313960c85f4b6dad56c","max":4987202208,"min":0,"orientation":"horizontal","style":"IPY_MODEL_26f3e8b8158b4dccb3de1b56a7706ad9","value":4987202208}},"0e8d376122e343378ff33e9a8b520588":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14df462ae83a4510b994bee3a5c0c7f7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"209d89e2f9fd46368338e5dd5ba9bcc5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_886db230753947c7be97102336fdf8cb","placeholder":"​","style":"IPY_MODEL_ba03cd17dd094cfc840d322b570d7a36","value":" 3.85G/3.85G [01:31&lt;00:00, 42.2MB/s]"}},"26b026eb94654279afb3692f1969b850":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26f3e8b8158b4dccb3de1b56a7706ad9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"27835c8e033645eba70bab60e20114a6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d81e63606f341b98e869e39d8f3b7b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e74e462a2474cbb94e8403aecb47084":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f1bb4bdf56c4b36a29bdcc34be76912":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f5539d800494ed3bf60b9e1a9b6c5e1","placeholder":"​","style":"IPY_MODEL_f41c077ef5ff4ea3800a23d3275ebc17","value":"tokenizer_config.json: 100%"}},"2f2dc663f8e8492f86ecd6015aeef10e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8d3414d297e34b91997d2c9cbae0bbab","IPY_MODEL_b0cbdf459ad348fba7acde917bb83440","IPY_MODEL_342597e4ad63432d99a64ada387efefe"],"layout":"IPY_MODEL_7b8bfa1a5e5144469810b2343f7c88b8"}},"2f5539d800494ed3bf60b9e1a9b6c5e1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"327983a483f24084b76c9bbe1e6952af":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"33c46db97bcd474899c48aa7c11d7fff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"342597e4ad63432d99a64ada387efefe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38e8e59405a6426f9b3ff3bd9789711f","placeholder":"​","style":"IPY_MODEL_37d5154de3364c78a862425ddc20ab3d","value":" 4.61M/4.61M [00:00&lt;00:00, 23.1MB/s]"}},"37d5154de3364c78a862425ddc20ab3d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"38e8e59405a6426f9b3ff3bd9789711f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"395e89abe1214a53a2f6a25d677de202":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a496eb47bdc4be88d444dde904f61ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b0d6d6cf7c544efadd4bdb980cc0f85":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4095eb26e4cf4a5da3de4ec1d58e5b51":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40de7d3859194efda0975a5f1b6f8751":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45022d2ad7f64df1bda26f65ce84f6a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4956ed1ffd314313960c85f4b6dad56c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"546c22a71fc646a2b82055fd66ac28ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9e2556394e0440d83e15a4bdf7ef549","placeholder":"​","style":"IPY_MODEL_b3724b7135af4683aab13275474c3395","value":"model-00001-of-00003.safetensors: 100%"}},"70a58e0a1dff45389fca1ab71322229c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2d81e63606f341b98e869e39d8f3b7b8","max":482,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9c652c09e8424a8ea8fd42df6f75893d","value":482}},"7636969ed3f641c5aae76bad98592e89":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b8bfa1a5e5144469810b2343f7c88b8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7bd80661adc84f3da8820920bc3491e2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"886db230753947c7be97102336fdf8cb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d3414d297e34b91997d2c9cbae0bbab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b0d6d6cf7c544efadd4bdb980cc0f85","placeholder":"​","style":"IPY_MODEL_edd309961a7340039733264e5a787868","value":"tokenizer.json: 100%"}},"925e2b584f4c4052b01ac4783c58a685":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4b894f82b03412a993e2ca8983e3882","placeholder":"​","style":"IPY_MODEL_beb28b70725b4be89c471565c32bc5d6","value":"model-00003-of-00003.safetensors: 100%"}},"9447a134d168473fa72c22f012087bfe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e74e462a2474cbb94e8403aecb47084","max":3852615520,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9ea8f2fe8ae1436bbec086cae1a375de","value":3852615520}},"947285eab75a4fc7acbce8a4ac4e8b69":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be7721c456f149cfa1d8522f3dfbd2f0","placeholder":"​","style":"IPY_MODEL_ae4db18bbccc4e2a8f5d8590fe833eac","value":" 716/716 [00:00&lt;00:00, 59.3kB/s]"}},"98ed34ff78ed407a83630bffec6bc800":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_925e2b584f4c4052b01ac4783c58a685","IPY_MODEL_9447a134d168473fa72c22f012087bfe","IPY_MODEL_209d89e2f9fd46368338e5dd5ba9bcc5"],"layout":"IPY_MODEL_14df462ae83a4510b994bee3a5c0c7f7"}},"9c652c09e8424a8ea8fd42df6f75893d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9ea8f2fe8ae1436bbec086cae1a375de":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a4a371b9284b47799534f7dc19872e3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a73564aebb034b6b8cb09b3a95ad04f8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af6e0663ad2c42f7b61c6a273d2714bb","placeholder":"​","style":"IPY_MODEL_e219e6adce7a4d6abd00322dcc6568c6","value":" 4.98G/4.98G [01:59&lt;00:00, 42.5MB/s]"}},"a83089299da2455c846aa450ada26238":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ac4dd32d174e4ceda4bc0938d535a26a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ae4db18bbccc4e2a8f5d8590fe833eac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"af538e762e414734b107a2dfac9e856d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a693361f4574cf08c81bf1fe3a63396","IPY_MODEL_d7eedfc42f2d4413be21561393d8e83f","IPY_MODEL_a73564aebb034b6b8cb09b3a95ad04f8"],"layout":"IPY_MODEL_3a496eb47bdc4be88d444dde904f61ce"}},"af6e0663ad2c42f7b61c6a273d2714bb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0cbdf459ad348fba7acde917bb83440":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7636969ed3f641c5aae76bad98592e89","max":4608376,"min":0,"orientation":"horizontal","style":"IPY_MODEL_efe1020ad471434c9a1a4ef4f7aa7d27","value":4608376}},"b3724b7135af4683aab13275474c3395":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8cbcbfd18c14ff19c619f7db7c425c8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_546c22a71fc646a2b82055fd66ac28ff","IPY_MODEL_0c022859280a40d8b10d147c3f8c9009","IPY_MODEL_064265e47535450697afb5af5413c286"],"layout":"IPY_MODEL_40de7d3859194efda0975a5f1b6f8751"}},"ba03cd17dd094cfc840d322b570d7a36":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb4ca1e071d340369240edf48708e0b7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc448cf3ab37444c88288b41a04132b7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_395e89abe1214a53a2f6a25d677de202","placeholder":"​","style":"IPY_MODEL_26b026eb94654279afb3692f1969b850","value":" 482/482 [00:00&lt;00:00, 40.8kB/s]"}},"bd8107edfad449649cc83cf813ac3930":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"be7721c456f149cfa1d8522f3dfbd2f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"beb28b70725b4be89c471565c32bc5d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c2b7b4f087f64ef7b0f1e23fba8b75a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c448a8f1cd284e449bc1dab26ca05fa5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4b894f82b03412a993e2ca8983e3882":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c81bf56821e945b9b0f55aaba5eaadb0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_02b5d1da86394f509aead940e2be66e3","IPY_MODEL_70a58e0a1dff45389fca1ab71322229c","IPY_MODEL_bc448cf3ab37444c88288b41a04132b7"],"layout":"IPY_MODEL_0e8d376122e343378ff33e9a8b520588"}},"cb850ac87616489c8c2567b3686cc696":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f1bb4bdf56c4b36a29bdcc34be76912","IPY_MODEL_db2e6d0af8344c6c864eebd2e0a30e85","IPY_MODEL_045ac1de256e4ef18b98aa590fd036cc"],"layout":"IPY_MODEL_0099c4658fa94e2da1dc62a429529f66"}},"ccda79f4cd894e5e8187e7be2da13e5b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7047798fe4e4501acdbb49beba1f365":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ede7777244524701b1a72a8f060bb156","IPY_MODEL_046a6e230692409cbe3a7b4b7c04a6ee","IPY_MODEL_947285eab75a4fc7acbce8a4ac4e8b69"],"layout":"IPY_MODEL_7bd80661adc84f3da8820920bc3491e2"}},"d7eedfc42f2d4413be21561393d8e83f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_327983a483f24084b76c9bbe1e6952af","max":4980945440,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d8a7a126e9374d679f9ab24921157283","value":4980945440}},"d8a7a126e9374d679f9ab24921157283":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"db2e6d0af8344c6c864eebd2e0a30e85":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a83089299da2455c846aa450ada26238","max":1229,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2b7b4f087f64ef7b0f1e23fba8b75a5","value":1229}},"e219e6adce7a4d6abd00322dcc6568c6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e753cbe825fe420aa44843f77241c7ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edd309961a7340039733264e5a787868":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ede7777244524701b1a72a8f060bb156":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_faf4a19a9298419fbb0361a627f260d8","placeholder":"​","style":"IPY_MODEL_ccda79f4cd894e5e8187e7be2da13e5b","value":"config.json: 100%"}},"efe1020ad471434c9a1a4ef4f7aa7d27":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f41c077ef5ff4ea3800a23d3275ebc17":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9e2556394e0440d83e15a4bdf7ef549":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"faf4a19a9298419fbb0361a627f260d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{"papermill":{"duration":0.03403,"end_time":"2024-10-27T08:43:06.85378","exception":false,"start_time":"2024-10-27T08:43:06.81975","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Make both T4 GPUs visiable to CUDA","metadata":{"papermill":{"duration":0.032633,"end_time":"2024-10-27T08:43:06.920546","exception":false,"start_time":"2024-10-27T08:43:06.887913","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os, math, numpy as np\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"","metadata":{"papermill":{"duration":0.0447,"end_time":"2024-10-27T08:43:06.998892","exception":false,"start_time":"2024-10-27T08:43:06.954192","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:04:35.566715Z","iopub.execute_input":"2024-10-31T04:04:35.567004Z","iopub.status.idle":"2024-10-31T04:04:35.576447Z","shell.execute_reply.started":"2024-10-31T04:04:35.566971Z","shell.execute_reply":"2024-10-31T04:04:35.575632Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Install vLLM","metadata":{"papermill":{"duration":0.033002,"end_time":"2024-10-27T08:43:07.064554","exception":false,"start_time":"2024-10-27T08:43:07.031552","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%time\n!pip uninstall -y torch\n!pip install -U --no-index --find-links=/kaggle/input/vllm-whl -U vllm\n!pip install -U --upgrade /kaggle/input/vllm-t4-fix/grpcio-1.62.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n!pip install -U --upgrade /kaggle/input/vllm-t4-fix/ray-2.11.0-cp310-cp310-manylinux2014_x86_64.whl","metadata":{"papermill":{"duration":155.073646,"end_time":"2024-10-27T08:45:42.171361","exception":false,"start_time":"2024-10-27T08:43:07.097715","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:04:35.578430Z","iopub.execute_input":"2024-10-31T04:04:35.578760Z","iopub.status.idle":"2024-10-31T04:07:27.159452Z","shell.execute_reply.started":"2024-10-31T04:04:35.578701Z","shell.execute_reply":"2024-10-31T04:07:27.158112Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: torch 2.4.0\nUninstalling torch-2.4.0:\n  Successfully uninstalled torch-2.4.0\nLooking in links: /kaggle/input/vllm-whl\nProcessing /kaggle/input/vllm-whl/vllm-0.4.0.post1-cp310-cp310-manylinux1_x86_64.whl\nProcessing /kaggle/input/vllm-whl/cmake-3.29.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from vllm)\nRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from vllm) (1.11.1.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from vllm) (5.9.3)\nRequirement already satisfied: ray>=2.9 in /opt/conda/lib/python3.10/site-packages (from vllm) (2.24.0)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from vllm) (0.2.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from vllm) (1.26.4)\nProcessing /kaggle/input/vllm-whl/torch-2.1.2-cp310-cp310-manylinux1_x86_64.whl (from vllm)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from vllm) (2.32.3)\nRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from vllm) (9.0.0)\nRequirement already satisfied: transformers>=4.39.1 in /opt/conda/lib/python3.10/site-packages (from vllm) (4.45.1)\nProcessing /kaggle/input/vllm-whl/xformers-0.0.23.post1-cp310-cp310-manylinux2014_x86_64.whl (from vllm)\nRequirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from vllm) (0.111.0)\nRequirement already satisfied: uvicorn[standard] in /opt/conda/lib/python3.10/site-packages (from vllm) (0.30.1)\nRequirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from vllm) (2.9.2)\nRequirement already satisfied: prometheus-client>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from vllm) (0.20.0)\nProcessing /kaggle/input/vllm-whl/pynvml-11.5.0-py3-none-any.whl (from vllm)\nProcessing /kaggle/input/vllm-whl/triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (from vllm)\nProcessing /kaggle/input/vllm-whl/outlines-0.0.34-py3-none-any.whl (from vllm)\nProcessing /kaggle/input/vllm-whl/tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (from vllm)\nProcessing /kaggle/input/vllm-whl/interegular-0.3.3-py37-none-any.whl (from outlines==0.0.34->vllm)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (3.1.4)\nProcessing /kaggle/input/vllm-whl/lark-1.1.9-py3-none-any.whl (from outlines==0.0.34->vllm)\nRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (1.6.0)\nRequirement already satisfied: cloudpickle in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (3.0.0)\nProcessing /kaggle/input/vllm-whl/diskcache-5.6.3-py3-none-any.whl (from outlines==0.0.34->vllm)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (1.14.1)\nRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (0.60.0)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (1.4.2)\nRequirement already satisfied: referencing in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (0.35.1)\nRequirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from outlines==0.0.34->vllm) (4.22.0)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.6.0->vllm) (2024.5.15)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->vllm) (3.15.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->vllm) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->vllm) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->vllm) (3.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.1.2->vllm) (2024.6.1)\nProcessing /kaggle/input/vllm-whl/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\nProcessing /kaggle/input/vllm-whl/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\nProcessing /kaggle/input/vllm-whl/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\nProcessing /kaggle/input/vllm-whl/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\nProcessing /kaggle/input/vllm-whl/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\nProcessing /kaggle/input/vllm-whl/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\nProcessing /kaggle/input/vllm-whl/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\nProcessing /kaggle/input/vllm-whl/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\nProcessing /kaggle/input/vllm-whl/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\nProcessing /kaggle/input/vllm-whl/nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\nProcessing /kaggle/input/vllm-whl/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (from torch==2.1.2->vllm)\nProcessing /kaggle/input/vllm-whl/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->vllm)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->vllm) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->vllm) (2.23.4)\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (8.1.7)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (1.0.8)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (21.3)\nRequirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (3.20.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (6.0.2)\nRequirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (1.3.1)\nRequirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray>=2.9->vllm) (1.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->vllm) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->vllm) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->vllm) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->vllm) (2024.8.30)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.1->vllm) (0.25.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.1->vllm) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.1->vllm) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.39.1->vllm) (4.66.4)\nRequirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (0.37.2)\nRequirement already satisfied: fastapi-cli>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (0.0.4)\nRequirement already satisfied: httpx>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (0.27.0)\nRequirement already satisfied: python-multipart>=0.0.7 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (0.0.9)\nRequirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (5.10.0)\nRequirement already satisfied: orjson>=3.2.1 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (3.10.4)\nRequirement already satisfied: email_validator>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->vllm) (2.1.1)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.14.0)\nRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.6.1)\nRequirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (1.0.1)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.19.0)\nRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (0.22.0)\nRequirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]->vllm) (12.0)\nRequirement already satisfied: dnspython>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from email_validator>=2.0.0->fastapi->vllm) (2.6.1)\nRequirement already satisfied: typer>=0.12.3 in /opt/conda/lib/python3.10/site-packages (from fastapi-cli>=0.0.2->fastapi->vllm) (0.12.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi->vllm) (4.4.0)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi->vllm) (1.0.5)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx>=0.23.0->fastapi->vllm) (1.3.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->outlines==0.0.34->vllm) (2.1.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ray>=2.9->vllm) (3.1.2)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->outlines==0.0.34->vllm) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->outlines==0.0.34->vllm) (2023.12.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->outlines==0.0.34->vllm) (0.18.1)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->outlines==0.0.34->vllm) (0.43.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.1.2->vllm) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx>=0.23.0->fastapi->vllm) (1.2.0)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm) (13.7.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.3->fastapi-cli>=0.0.2->fastapi->vllm) (0.1.2)\nInstalling collected packages: triton, pynvml, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lark, interegular, diskcache, cmake, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, xformers, outlines, vllm\n  Attempting uninstall: pynvml\n    Found existing installation: pynvml 11.4.1\n    Uninstalling pynvml-11.4.1:\n      Successfully uninstalled pynvml-11.4.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nucxx 0.39.1 requires libucx>=1.15.0, which is not installed.\ndask-cuda 24.8.2 requires pynvml<11.5,>=11.0.0, but you have pynvml 11.5.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed cmake-3.29.0.1 diskcache-5.6.3 interegular-0.3.3 lark-1.1.9 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 outlines-0.0.34 pynvml-11.5.0 tiktoken-0.6.0 torch-2.1.2 triton-2.1.0 vllm-0.4.0.post1 xformers-0.0.23.post1\nProcessing /kaggle/input/vllm-t4-fix/grpcio-1.62.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\ngrpcio is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\nProcessing /kaggle/input/vllm-t4-fix/ray-2.11.0-cp310-cp310-manylinux2014_x86_64.whl\nRequirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (8.1.7)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (3.15.1)\nRequirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (4.22.0)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (1.0.8)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (21.3)\nRequirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (3.20.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (6.0.2)\nRequirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (1.3.1)\nRequirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (1.4.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray==2.11.0) (2.32.3)\nRequirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.11.0) (23.2.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.11.0) (2023.12.1)\nRequirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.11.0) (0.35.1)\nRequirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.11.0) (0.18.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ray==2.11.0) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.11.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.11.0) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.11.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.11.0) (2024.8.30)\nInstalling collected packages: ray\n  Attempting uninstall: ray\n    Found existing installation: ray 2.24.0\n    Uninstalling ray-2.24.0:\n      Successfully uninstalled ray-2.24.0\nSuccessfully installed ray-2.11.0\nCPU times: user 1.84 s, sys: 451 ms, total: 2.29 s\nWall time: 2min 51s\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Some Configuration","metadata":{"papermill":{"duration":0.038262,"end_time":"2024-10-27T08:45:42.247565","exception":false,"start_time":"2024-10-27T08:45:42.209303","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# In DEBUG mode, infer only on 5 problems\nDEBUG = False\n# Number of candidate solutions to generate\nK = 12\nDEPTH = 4\nTEMPERATURE = 0.8\nTOP_P = 0.9\nBATCH_SIZE = 64","metadata":{"papermill":{"duration":0.046185,"end_time":"2024-10-27T08:45:42.330812","exception":false,"start_time":"2024-10-27T08:45:42.284627","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:07:27.161839Z","iopub.execute_input":"2024-10-31T04:07:27.162285Z","iopub.status.idle":"2024-10-31T04:07:27.167532Z","shell.execute_reply.started":"2024-10-31T04:07:27.162220Z","shell.execute_reply":"2024-10-31T04:07:27.166527Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{"papermill":{"duration":0.039038,"end_time":"2024-10-27T08:45:42.406746","exception":false,"start_time":"2024-10-27T08:45:42.367708","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import vllm\nimport re\nimport csv\nimport torch\nimport gc\nfrom tqdm import tqdm\nimport pandas as pd\nfrom queue import Queue, Empty\nimport os\nimport re\nimport signal\nimport subprocess\nimport tempfile\nfrom collections import Counter\nfrom contextlib import contextmanager\n\nimport threading\nfrom concurrent.futures import ThreadPoolExecutor, as_completed","metadata":{"papermill":{"duration":5.181556,"end_time":"2024-10-27T08:45:47.626636","exception":false,"start_time":"2024-10-27T08:45:42.44508","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:07:27.168742Z","iopub.execute_input":"2024-10-31T04:07:27.169082Z","iopub.status.idle":"2024-10-31T04:07:32.648681Z","shell.execute_reply.started":"2024-10-31T04:07:27.169041Z","shell.execute_reply":"2024-10-31T04:07:32.647872Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-10-31 04:07:31,522\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Python Code Execution Environment","metadata":{"papermill":{"duration":0.037123,"end_time":"2024-10-27T08:45:47.701751","exception":false,"start_time":"2024-10-27T08:45:47.664628","status":"completed"},"tags":[]}},{"cell_type":"code","source":"1","metadata":{"papermill":{"duration":0.046903,"end_time":"2024-10-27T08:45:47.785939","exception":false,"start_time":"2024-10-27T08:45:47.739036","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:07:32.651228Z","iopub.execute_input":"2024-10-31T04:07:32.651801Z","iopub.status.idle":"2024-10-31T04:07:32.658704Z","shell.execute_reply.started":"2024-10-31T04:07:32.651755Z","shell.execute_reply":"2024-10-31T04:07:32.657817Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"1"},"metadata":{}}]},{"cell_type":"markdown","source":"## Find Python code blocks within text","metadata":{"papermill":{"duration":0.037104,"end_time":"2024-10-27T08:45:47.860044","exception":false,"start_time":"2024-10-27T08:45:47.82294","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def find_python_blocks(text):\n    blocks = re.findall(r\"(```python.*?```)\", text, re.DOTALL)\n    # filter blocks by trying to convert them to float or int\n    filtered_blocks = []\n    for block in blocks:\n        code = block[len(\"```python\"):-len(\"```\")].strip()\n        try:\n            x = int(code)\n        except:\n            filtered_blocks.append(code)\n            continue\n        try:\n            x = float(code)\n        except:\n            filtered_blocks.append(code)\n    return filtered_blocks        ","metadata":{"papermill":{"duration":0.045967,"end_time":"2024-10-27T08:45:47.943822","exception":false,"start_time":"2024-10-27T08:45:47.897855","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:07:32.659774Z","iopub.execute_input":"2024-10-31T04:07:32.660139Z","iopub.status.idle":"2024-10-31T04:07:32.671153Z","shell.execute_reply.started":"2024-10-31T04:07:32.660091Z","shell.execute_reply":"2024-10-31T04:07:32.670441Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Class to Execute Python code (adopted from Numina)","metadata":{"papermill":{"duration":0.037455,"end_time":"2024-10-27T08:45:48.01859","exception":false,"start_time":"2024-10-27T08:45:47.981135","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class PythonREPL:\n    def __init__(self, timeout=5):\n        self.timeout = timeout\n    # handles timeout\n    @contextmanager\n    def time_limit(self, seconds):\n        def signal_handler(*_):\n            raise TimeoutError(f\"Timed out after {seconds} seconds.\")\n\n        signal.signal(signal.SIGALRM, signal_handler)\n        signal.alarm(seconds)\n        try:\n            yield\n        finally:\n            signal.alarm(0)\n\n    def __call__(self, query):\n        query = \"import math\\nimport numpy as np\\nimport sympy as sp\\n\" + query\n        query = query.strip().split(\"\\n\")\n        if \"print(\" not in query[-1]:\n            if \"#\" in query[-1]:\n                query[-1] = query[-1].split(\"#\")[0]\n            query[-1] = \"print(\" + query[-1] + \")\"\n        query = \"\\n\".join(query)\n        with tempfile.TemporaryDirectory() as temp_dir:\n            temp_file_path = os.path.join(temp_dir, \"tmp.py\")\n            with open(temp_file_path, \"w\", encoding=\"utf-8\") as f:\n                f.write(query)\n            with self.time_limit(self.timeout):\n                result = subprocess.run(\n                    [\"python3\", temp_file_path],\n                    capture_output=True,\n                    check=False,\n                    text=True,\n                    timeout=self.timeout,\n                )\n                if result.returncode == 0:\n                    output = result.stdout\n                    return True, output.strip()\n                error_msg = result.stderr.strip()\n                msgs = error_msg.split(\"\\n\")\n                new_msgs = []\n                want_next = False\n                for m in msgs:\n                    if \"Traceback\" in m:\n                        new_msgs.append(m)\n                    elif m == msgs[-1]:\n                        new_msgs.append(m)\n                    elif temp_file_path in m:\n                        st = m.index('\"/') + 1 if '\"/' in m else 0\n                        ed = m.index(temp_file_path) + 1 if temp_file_path in m else None\n                        clr = m[st:ed] if not ed else m[st:]\n                        m = m.replace(clr, \"\")\n                        new_msgs.append(m)\n                        want_next = True\n                    elif want_next:\n                        new_msgs.append(m)\n                        want_next = False\n                error_msg = \"\\n\".join(new_msgs)\n                return False, error_msg.strip()","metadata":{"papermill":{"duration":0.053719,"end_time":"2024-10-27T08:45:48.109485","exception":false,"start_time":"2024-10-27T08:45:48.055766","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:07:32.672583Z","iopub.execute_input":"2024-10-31T04:07:32.672947Z","iopub.status.idle":"2024-10-31T04:07:32.688497Z","shell.execute_reply.started":"2024-10-31T04:07:32.672906Z","shell.execute_reply":"2024-10-31T04:07:32.687606Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Execute a Python code block","metadata":{"papermill":{"duration":0.0373,"end_time":"2024-10-27T08:45:48.183928","exception":false,"start_time":"2024-10-27T08:45:48.146628","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def execute(executor, code):\n    success = False\n    for lib in (\"subprocess\", \"venv\"):\n        if lib in code:\n            output = f\"{lib} is not allowed\"\n            outputs.append(output)\n            successes.append(success)\n            continue\n    try:\n        success, output = executor(code)\n    except TimeoutError as e:\n        output = str(e)\n\n    output = output.strip()\n    \n    return output, success","metadata":{"papermill":{"duration":0.04653,"end_time":"2024-10-27T08:45:48.267876","exception":false,"start_time":"2024-10-27T08:45:48.221346","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:07:32.689574Z","iopub.execute_input":"2024-10-31T04:07:32.689855Z","iopub.status.idle":"2024-10-31T04:07:32.709149Z","shell.execute_reply.started":"2024-10-31T04:07:32.689817Z","shell.execute_reply":"2024-10-31T04:07:32.708304Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Test by running some python code","metadata":{"papermill":{"duration":0.037065,"end_time":"2024-10-27T08:45:48.342304","exception":false,"start_time":"2024-10-27T08:45:48.305239","status":"completed"},"tags":[]}},{"cell_type":"code","source":"text = \"\"\"Block 1\n```python\ns = 0\nfor i in range(100):\n    s += i\nprint(s)\n```\nBlock 2\n```python\n2**12\n```\nBlock 3\n```python\n3\n```\n\"\"\"","metadata":{"papermill":{"duration":0.044606,"end_time":"2024-10-27T08:45:48.423919","exception":false,"start_time":"2024-10-27T08:45:48.379313","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:07:32.710229Z","iopub.execute_input":"2024-10-31T04:07:32.710542Z","iopub.status.idle":"2024-10-31T04:07:32.729901Z","shell.execute_reply.started":"2024-10-31T04:07:32.710511Z","shell.execute_reply":"2024-10-31T04:07:32.728935Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"blocks = find_python_blocks(text)\nblocks","metadata":{"papermill":{"duration":0.051797,"end_time":"2024-10-27T08:45:48.515244","exception":false,"start_time":"2024-10-27T08:45:48.463447","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:07:32.731090Z","iopub.execute_input":"2024-10-31T04:07:32.731403Z","iopub.status.idle":"2024-10-31T04:07:32.744962Z","shell.execute_reply.started":"2024-10-31T04:07:32.731372Z","shell.execute_reply":"2024-10-31T04:07:32.744241Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['s = 0\\nfor i in range(100):\\n    s += i\\nprint(s)', '2**12']"},"metadata":{}}]},{"cell_type":"code","source":"executor = PythonREPL()\noutputs = [execute(executor, block) for block in blocks]\noutputs","metadata":{"papermill":{"duration":1.243786,"end_time":"2024-10-27T08:45:49.796495","exception":false,"start_time":"2024-10-27T08:45:48.552709","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:07:32.749424Z","iopub.execute_input":"2024-10-31T04:07:32.749785Z","iopub.status.idle":"2024-10-31T04:07:33.947357Z","shell.execute_reply.started":"2024-10-31T04:07:32.749755Z","shell.execute_reply":"2024-10-31T04:07:33.946393Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"[('4950', True), ('4096', True)]"},"metadata":{}}]},{"cell_type":"code","source":"# for block, output in zip(blocks, outputs):\n#     print(f\"\"\"\n# ```python\n# {block}\n# ```\n# ```output\n# {output[0]}\n# ```\"\"\"\n#     )","metadata":{"papermill":{"duration":0.047921,"end_time":"2024-10-27T08:45:49.88264","exception":false,"start_time":"2024-10-27T08:45:49.834719","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:07:33.948497Z","iopub.execute_input":"2024-10-31T04:07:33.948811Z","iopub.status.idle":"2024-10-31T04:07:33.952858Z","shell.execute_reply.started":"2024-10-31T04:07:33.948779Z","shell.execute_reply":"2024-10-31T04:07:33.951952Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Load Model on vLLM","metadata":{"papermill":{"duration":0.037126,"end_time":"2024-10-27T08:45:49.957138","exception":false,"start_time":"2024-10-27T08:45:49.920012","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## We use the Qwen 2.5 7b Instruct Model here by Alibaba. You should explore other models.","metadata":{"papermill":{"duration":0.049055,"end_time":"2024-10-27T08:45:50.049815","exception":false,"start_time":"2024-10-27T08:45:50.00076","status":"completed"},"tags":[]}},{"cell_type":"code","source":"llm = vllm.LLM(\n    \"Qwen/Qwen2.5-32B-Instruct-AWQ\",\n    tensor_parallel_size=2, \n    gpu_memory_utilization=0.95, \n    trust_remote_code=True,\n    dtype=\"half\", \n    enforce_eager=True,\n    max_model_len=6500,\n)\ntokenizer = llm.get_tokenizer()","metadata":{"papermill":{"duration":171.446108,"end_time":"2024-10-27T08:48:41.533975","exception":false,"start_time":"2024-10-27T08:45:50.087867","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:07:33.954164Z","iopub.execute_input":"2024-10-31T04:07:33.954490Z","iopub.status.idle":"2024-10-31T04:10:40.443660Z","shell.execute_reply.started":"2024-10-31T04:07:33.954457Z","shell.execute_reply":"2024-10-31T04:10:40.439118Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/841 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6c0d28eab794c079ef12b1875c656eb"}},"metadata":{}},{"name":"stdout","text":"WARNING 10-31 04:07:34 config.py:211] awq quantization is not fully optimized yet. The speed can be slower than non-quantized models.\n","output_type":"stream"},{"name":"stderr","text":"2024-10-31 04:07:37,163\tINFO worker.py:1749 -- Started a local Ray instance.\n","output_type":"stream"},{"name":"stdout","text":"INFO 10-31 04:07:38 llm_engine.py:74] Initializing an LLM engine (v0.4.0.post1) with config: model='Qwen/Qwen2.5-32B-Instruct-AWQ', tokenizer='Qwen/Qwen2.5-32B-Instruct-AWQ', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=6500, download_dir=None, load_format=auto, tensor_parallel_size=2, disable_custom_all_reduce=True, quantization=awq, enforce_eager=True, kv_cache_dtype=auto, device_config=cuda, seed=0)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f81c49475fd45a48ca456a1ba7646c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b4574b2a6ca4d1ea6b0035f19d61f25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2338b46f5976457ab89d37e8a7fb3dfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49f185caf45e44338b478bc2433dcae9"}},"metadata":{}},{"name":"stdout","text":"INFO 10-31 04:07:48 selector.py:40] Cannot use FlashAttention backend for Volta and Turing GPUs.\nINFO 10-31 04:07:48 selector.py:25] Using XFormers backend.\n\u001b[36m(RayWorkerVllm pid=404)\u001b[0m INFO 10-31 04:07:49 selector.py:40] Cannot use FlashAttention backend for Volta and Turing GPUs.\n\u001b[36m(RayWorkerVllm pid=404)\u001b[0m INFO 10-31 04:07:49 selector.py:25] Using XFormers backend.\nINFO 10-31 04:07:49 pynccl_utils.py:45] vLLM is using nccl==2.18.1\n\u001b[36m(RayWorkerVllm pid=404)\u001b[0m INFO 10-31 04:07:49 pynccl_utils.py:45] vLLM is using nccl==2.18.1\nINFO 10-31 04:07:50 weight_utils.py:177] Using model weights format ['*.safetensors']\n\u001b[36m(RayWorkerVllm pid=404)\u001b[0m INFO 10-31 04:07:50 weight_utils.py:177] Using model weights format ['*.safetensors']\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00005.safetensors:   0%|          | 0.00/3.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7ebddbb82cb4ee59f75bcf048961510"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00005.safetensors:   0%|          | 0.00/3.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da9395465fb542acbab10ca04447778d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00005.safetensors:   0%|          | 0.00/3.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"583408307655438e8b54e6211ff8ffb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00005.safetensors:   0%|          | 0.00/3.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0941e355d8ed45ec88a3c50a0d34ce49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00005.safetensors:   0%|          | 0.00/3.48G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62427e3af353445c91f9276bc9ebe58d"}},"metadata":{}},{"name":"stdout","text":"INFO 10-31 04:10:25 model_runner.py:104] Loading model weights took 9.0933 GB\n\u001b[36m(RayWorkerVllm pid=404)\u001b[0m INFO 10-31 04:10:25 model_runner.py:104] Loading model weights took 9.0933 GB\nINFO 10-31 04:10:36 ray_gpu_executor.py:240] # GPU blocks: 1191, # CPU blocks: 2048\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Utilites","metadata":{"papermill":{"duration":0.045678,"end_time":"2024-10-27T08:48:41.625872","exception":false,"start_time":"2024-10-27T08:48:41.580194","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Extract boxed answer","metadata":{"papermill":{"duration":0.051138,"end_time":"2024-10-27T08:48:41.722635","exception":false,"start_time":"2024-10-27T08:48:41.671497","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def extract_answer(text):\n    # find right most boxed answer\n    def last_boxed_only_string(text):\n        idx = text.rfind(\"\\\\boxed\")\n        if idx < 0:\n            idx = text.rfind(\"\\\\fbox\")\n            if idx < 0:\n                return None\n        i = idx\n        right_brace_idx = None\n        num_left_braces_open = 0\n        while i < len(text):\n            if text[i] == \"{\":\n                num_left_braces_open += 1\n            if text[i] == \"}\":\n                num_left_braces_open -= 1\n                if num_left_braces_open == 0:\n                    right_brace_idx = i\n                    break\n            i += 1\n        if right_brace_idx is None:\n            return None\n        return text[idx : right_brace_idx + 1]\n    # get content of boxed\n    def remove_boxed(boxed):\n        left = \"\\\\boxed{\"\n        try:\n            assert boxed[: len(left)] == left\n            assert boxed[-1] == \"}\"\n            length = len(left)\n            return boxed[length:-1]\n        except Exception:\n            return None\n\n    boxed = last_boxed_only_string(text)\n    if boxed is None:\n        return None\n    answer = remove_boxed(boxed)\n    return answer","metadata":{"papermill":{"duration":0.059459,"end_time":"2024-10-27T08:48:41.829116","exception":false,"start_time":"2024-10-27T08:48:41.769657","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:10:40.449272Z","iopub.execute_input":"2024-10-31T04:10:40.452043Z","iopub.status.idle":"2024-10-31T04:10:40.483335Z","shell.execute_reply.started":"2024-10-31T04:10:40.451922Z","shell.execute_reply":"2024-10-31T04:10:40.480965Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Majority vote (select the most occuring answer)","metadata":{"papermill":{"duration":0.04321,"end_time":"2024-10-27T08:48:41.915353","exception":false,"start_time":"2024-10-27T08:48:41.872143","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Define the majority voting function to get the most common answer\ndef majority_vote(answers):\n    answers = [answer for answer in answers if answer is not None]\n\n    if not answers:\n        return None\n    # count the occurence of each answer\n    counts = {}\n    for answer in answers:\n        if answer in counts:\n            counts[answer] += 1\n        else:\n            counts[answer] = 1\n\n    max_answer = None\n    max_count = 0\n    \n    for answer, count in counts.items():\n        if count > max_count:\n            max_answer = answer\n            max_count = count\n    \n    return max_answer","metadata":{"papermill":{"duration":0.054317,"end_time":"2024-10-27T08:48:42.013283","exception":false,"start_time":"2024-10-27T08:48:41.958966","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:10:40.486488Z","iopub.execute_input":"2024-10-31T04:10:40.487301Z","iopub.status.idle":"2024-10-31T04:10:40.535311Z","shell.execute_reply.started":"2024-10-31T04:10:40.487177Z","shell.execute_reply":"2024-10-31T04:10:40.533974Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# TIR Agent","metadata":{"papermill":{"duration":0.045062,"end_time":"2024-10-27T08:48:42.100813","exception":false,"start_time":"2024-10-27T08:48:42.055751","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# class TIRAgent:\n#     def __init__(self, problem_id, id, problem, tokenizer, max_depth, log):\n#         # problem id\n#         self.problem_id = problem_id\n#         # id of the agent\n#         self.id = id\n#         # number of LLM turns\n#         self.depth = 1\n#         # maximum number of turns allowed\n#         self.max_depth = max_depth\n#         # LLM's tokenizer\n#         self.tokenizer = tokenizer\n#         # Problem statement\n#         self.problem = problem\n#         # Chat Messages\n#         self.messages = [\n#             {\n#                \"role\": \"user\", \n#                 \"content\": f\"\"\"Here is a math problem:\n# {self.problem}\n# Please solve the problem step by step, providing Python code at each step to verify your reasoning.\n# Break your reasoning into:\n# 1. Problem understanding.\n# 2. Step-by-step logical breakdown.\n# 3. Python code to verify.\n# Finally, provide the non-negative integer answer within \\\\boxed{{}}.\"\"\"\n#             }\n#         ]\n#         # Last response from the LLM\n#         self.last_response = None\n#         # Code blocks from the last response\n#         self.blocks = []\n#         # Answers that the LLM generated in \\boxed{}\n#         self.answers = []\n#         # No python code generated in last response or max_depth reached\n#         self.is_complete = False\n#         # File to log answers\n#         self.log = log\n#         # Next prompt to the LLM\n#         self.next_prompt = None\n        \n#     def complete(self):\n#         # Is the Agent done\n#         return self.is_complete\n    \n#     def add_response(self, response, executor):\n#         self.depth += 1\n#         # Remember this response\n#         self.last_response = response\n#         # Add this to the messages history\n#         self.messages.append({\"role\": \"assistant\", \"content\": response})\n#         # Extract python blocks\n#         self.blocks = find_python_blocks(response)\n#         # Extract answer from the generated text, if present\n#         answer = extract_answer(response)\n#         if answer is not None:\n#             self.answers.append(answer)\n#         # Is it done?\n#         self.is_complete = not self._should_continue()\n#         # If not, use the python executor to create next prompt\n#         if not self.is_complete:\n#             self.next_prompt = self._next_prompt(executor)   \n#             self.messages.append({\"role\": \"user\", \"content\": self.next_prompt})\n    \n#     def _should_continue(self):        \n#         # Quit if max_depth number of turns reached\n#         if self.depth >= self.max_depth:\n#             return False\n#         # If python code is generated, we can continue\n#         elif len(self.blocks) > 0:\n#             return True\n#         return False\n    \n#     def _next_prompt(self, executor):\n#         assert not self.is_complete\n#         assert len(self.blocks) > 0\n#         # Get code result from python execution\n#         output, status = execute(executor, self.blocks[-1])\n        \n#         prompt = ''\n#         # If code succeeds, give the output\n#         if status:\n#             prompt = f\"\"\"The Python code you provided executed successfully with the following output:\n# ```python\n# {self.blocks[-1]}\n\n# ```\n# ```output\n# {output}\n# ```\"\"\"\n#         # if code fails, give the error\n#         else:\n#             prompt = f\"\"\"The python code you provided gives the following error:\n# ```python\n# {self.blocks[-1]}\n# ```\n# ```output\n# {output}\n# Please review the code, correct any mistakes, and provide a new solution with updated logic and code.\n# ```\"\"\"\n#         if self.depth == self.max_depth - 1:\n#             prompt += f\"\\nSince we are nearing the limit of {self.max_depth} attempts, please finalize your response and double-check all steps.\"\n#         return prompt\n    \n    \n#     def next_message(self):\n#         assert not self.is_complete \n#         # apply chat template to get the text\n#         text = self.tokenizer.apply_chat_template(\n#             self.messages,\n#             tokenize=False,\n#             add_generation_prompt=True\n#         )\n        \n#         return text\n        \n    \n#     def final_answer(self):\n#         # if there no answers yet, we have to return None\n#         ans = None\n#         # otherwise return the latest answer\n#         if len(self.answers) > 0:\n#             ans = self.answers[-1]\n#         # log to file\n#         if self.log:\n#             self.log.writerow([self.problem_id, self.id, ans])\n#         # try to convert to integer\n#         try:\n#             ans = int(ans)\n#         except:\n#             ans = None\n        \n#         return ans","metadata":{"papermill":{"duration":0.096047,"end_time":"2024-10-27T08:48:42.257732","exception":false,"start_time":"2024-10-27T08:48:42.161685","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:10:40.539397Z","iopub.execute_input":"2024-10-31T04:10:40.540852Z","iopub.status.idle":"2024-10-31T04:10:40.567292Z","shell.execute_reply.started":"2024-10-31T04:10:40.540740Z","shell.execute_reply":"2024-10-31T04:10:40.565250Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"class TIRAgent:\n    def __init__(self, problem_id, id, problem, tokenizer,max_depth, log):\n        # problem id\n        self.problem_id = problem_id\n        # id of the agent\n        self.id = id\n        # number of LLM turns\n        self.depth = 1\n        # maximum number of turns allowed\n        self.max_depth = max_depth\n        # LLM's tokenizer\n        self.tokenizer = tokenizer\n        # Problem statement\n        self.problem = problem\n        # Chat Messages\n        self.messages = [\n            {\n               \"role\": \"user\", \n                \"content\": f\"\"\"Here is a math problem in Bengali:\n{self.problem}\nThe answer is a non-negative integer. Please reason step by step to solve the problem above. Provide python code to verify your reasoning.\nPut your final integer answer within \\\\boxed{{}}.\"\"\"\n            }\n        ]\n        # Last response from the LLM\n        self.last_response = None\n        # Code blocks from the last response\n        self.blocks = []\n        # Answers that the LLM generated in \\boxed{}\n        self.answers = []\n        # No python code generated in last response or max_depth reached\n        self.is_complete = False\n        # File to log answers\n        self.log = log\n        # Next prompt to the LLM\n        self.next_prompt = None\n        self.is_answer_checked = False\n        \n    def complete(self):\n        # is the Agent done\n        return self.is_complete\n    \n    def add_response(self, response, executor):\n        self.depth += 1\n        # remember this response\n        self.last_response = response\n        # add this to the messages history\n        self.messages.append({\"role\": \"assistant\", \"content\": response})\n        # extract python blocks\n        self.blocks = find_python_blocks(response)\n        # extract answer from the generated text, if present\n        answer = extract_answer(response)\n        if answer is not None:\n            self.answers.append(answer)\n        # is it done?\n        self.is_complete = not self._should_continue()\n        # if not, use the python executor to create next prompt\n        if not self.is_complete:\n            self.next_prompt = self._next_prompt(executor)   \n            self.messages.append({\"role\": \"user\", \"content\": self.next_prompt})\n    \n    def _should_continue(self):        \n        # quit if max_depth number of turns reached\n        if self.depth >= self.max_depth:\n            return False\n        # if no python code generated, we can stop now\n        elif len(self.blocks) > 0:\n            return True\n        return False\n    \n    def _next_prompt(self, executor):\n        assert not self.is_complete\n        assert len(self.blocks) > 0\n        # get code result from python execution\n        output, status = execute(executor, self.blocks[-1])\n        add_to_prompt = ''\n        if self.is_answer_checked:\n            add_to_prompt += '\\nverify if the output matches your reasoning, if it does give the final answer within \\\\boxed{{}}.'\n        else:\n            add_to_prompt += '\\ngive me another python code to check if the output actually solves the problem.'\n            \n        \n        prompt = ''\n        # if code succeeds give the output\n        if status:\n            prompt = f\"\"\"The python code you provided gives the following output:\n```python\n{self.blocks[-1]}\n```\n```output\n{output}  \n```{add_to_prompt}\"\"\"\n            self.is_answer_checked = True\n        # if code fails, give the error\n        else:\n            prompt = f\"\"\"The python code you provided gives the following error:\n```python\n{self.blocks[-1]}\n```\n```output\n{output} \n```\\nPlease fix the code errors and continue solving the problem\"\"\"\n            self.is_answer_checked = False\n        return prompt\n    \n    \n    def next_message(self):\n        assert not self.is_complete \n        # apply chat template to get the text\n        text = self.tokenizer.apply_chat_template(\n            self.messages,\n            tokenize=False,\n            add_generation_prompt=True\n        )\n        \n        return text\n        \n    \n    def final_answer(self):\n        # if there no answers yet, we have to return None\n        ans = None\n        # otherwise return the latest answer\n        if len(self.answers) > 0:\n            ans = self.answers[-1]\n        # log to file\n        if self.log:\n            self.log.writerow([self.problem_id, self.id, ans])\n        # try to convert to integer\n        try:\n            ans = int(ans)\n        except:\n            ans = None\n        \n        return ans        ","metadata":{"papermill":{"duration":0.133662,"end_time":"2024-10-27T08:48:42.455377","exception":false,"start_time":"2024-10-27T08:48:42.321715","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:10:40.571625Z","iopub.execute_input":"2024-10-31T04:10:40.572766Z","iopub.status.idle":"2024-10-31T04:10:40.618237Z","shell.execute_reply.started":"2024-10-31T04:10:40.572580Z","shell.execute_reply":"2024-10-31T04:10:40.616211Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Sc-TIR Agent","metadata":{"papermill":{"duration":0.062996,"end_time":"2024-10-27T08:48:42.581864","exception":false,"start_time":"2024-10-27T08:48:42.518868","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class SCTIRAgent:\n    def __init__(self, problem_id, problem, tokenizer,samples, max_depth, log):\n        # problem id\n        self.problem_id = problem_id\n        # problem statement\n        self.problem = problem\n        # LLM's tokenizer\n        self.tokenizer = tokenizer\n        # number of TIRAgents to create\n        self.samples = samples\n        # maximum number of turns\n        self.max_depth = max_depth\n        # TIR Agents\n        self.agents = [TIRAgent(problem_id, i, problem, tokenizer, max_depth, log) for i in range(samples)]\n        # log file\n        self.log = log\n    \n    def complete(self):\n        # only complete when all agents are done\n        for agent in self.agents:\n            if not agent.complete():\n                return False\n        return True\n        \n    def get_ready_agents(self):\n        # return agents that are not complete yet\n        ready_agents = []\n        for agent in self.agents:\n            if not agent.complete():\n                ready_agents.append(agent)\n        return ready_agents\n    \n    def final_answer(self):\n        # majority vote agent answers\n        assert self.complete()\n        answers = [agent.final_answer() for agent in self.agents]\n        answer = majority_vote(answers)\n        if answer is None:\n            return 0\n        return answer","metadata":{"papermill":{"duration":0.096214,"end_time":"2024-10-27T08:48:42.741839","exception":false,"start_time":"2024-10-27T08:48:42.645625","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:10:40.622289Z","iopub.execute_input":"2024-10-31T04:10:40.623131Z","iopub.status.idle":"2024-10-31T04:10:40.650748Z","shell.execute_reply.started":"2024-10-31T04:10:40.623001Z","shell.execute_reply":"2024-10-31T04:10:40.648249Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Load Test Set","metadata":{"papermill":{"duration":0.063708,"end_time":"2024-10-27T08:48:42.86946","exception":false,"start_time":"2024-10-27T08:48:42.805752","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#test_df = pd.read_csv('/kaggle/input/translated-test-df/translated_test_df.csv')\n\ntest_df = pd.read_csv('/kaggle/input/dlsprint3/test.csv')\ntest_df.sample(5)","metadata":{"papermill":{"duration":0.197453,"end_time":"2024-10-27T08:48:43.130958","exception":false,"start_time":"2024-10-27T08:48:42.933505","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:10:40.654155Z","iopub.execute_input":"2024-10-31T04:10:40.655065Z","iopub.status.idle":"2024-10-31T04:10:40.849861Z","shell.execute_reply.started":"2024-10-31T04:10:40.654944Z","shell.execute_reply":"2024-10-31T04:10:40.847798Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"    ID                                            Problem\n26  26  $x$, $y$ এবং $z$ এমন বাস্তব সংখ্যা যেন $(4^x +...\n86  86  একটি ত্রিভুজের বৃহত্তম কোণ 80° হলে, ক্ষুদ্রতম ...\n2    2  ধরো $f(x) = x^{67-x^{67-x^{67-\\dots}}}$, যেখান...\n55  55  তোমার কাছে অসীম সংখ্যক 2,3 এবং 4 টাকার নোট রয়ে...\n75  75  যদি $a = 3$ এবং $r = \\frac{1}{3}$ হয়, তাহলে\\n\\...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Problem</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>26</th>\n      <td>26</td>\n      <td>$x$, $y$ এবং $z$ এমন বাস্তব সংখ্যা যেন $(4^x +...</td>\n    </tr>\n    <tr>\n      <th>86</th>\n      <td>86</td>\n      <td>একটি ত্রিভুজের বৃহত্তম কোণ 80° হলে, ক্ষুদ্রতম ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>ধরো $f(x) = x^{67-x^{67-x^{67-\\dots}}}$, যেখান...</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>55</td>\n      <td>তোমার কাছে অসীম সংখ্যক 2,3 এবং 4 টাকার নোট রয়ে...</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>75</td>\n      <td>যদি $a = 3$ এবং $r = \\frac{1}{3}$ হয়, তাহলে\\n\\...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Load 5 problems since we are short on time","metadata":{"papermill":{"duration":0.045784,"end_time":"2024-10-27T08:48:43.244103","exception":false,"start_time":"2024-10-27T08:48:43.198319","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# if DEBUG:\n#     test_df = test_df[:5]\n#     torch.cuda.empty_cache()\n#     gc.collect()","metadata":{"papermill":{"duration":0.059553,"end_time":"2024-10-27T08:48:43.347094","exception":false,"start_time":"2024-10-27T08:48:43.287541","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:10:40.852708Z","iopub.execute_input":"2024-10-31T04:10:40.854668Z","iopub.status.idle":"2024-10-31T04:10:40.863307Z","shell.execute_reply.started":"2024-10-31T04:10:40.854612Z","shell.execute_reply":"2024-10-31T04:10:40.860011Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Configure LLM and Python REPL","metadata":{"papermill":{"duration":0.043248,"end_time":"2024-10-27T08:48:43.434606","exception":false,"start_time":"2024-10-27T08:48:43.391358","status":"completed"},"tags":[]}},{"cell_type":"code","source":"sampling_params = vllm.SamplingParams(max_tokens=2048, temperature=TEMPERATURE, top_p=TOP_P, stop=[\"```output\", \"```\\noutput\"])\nexecutor = PythonREPL()","metadata":{"papermill":{"duration":0.054144,"end_time":"2024-10-27T08:48:43.53106","exception":false,"start_time":"2024-10-27T08:48:43.476916","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:10:40.868840Z","iopub.execute_input":"2024-10-31T04:10:40.870512Z","iopub.status.idle":"2024-10-31T04:10:40.883476Z","shell.execute_reply.started":"2024-10-31T04:10:40.870336Z","shell.execute_reply":"2024-10-31T04:10:40.881001Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Run the Agents","metadata":{"papermill":{"duration":0.04121,"end_time":"2024-10-27T08:48:43.613339","exception":false,"start_time":"2024-10-27T08:48:43.572129","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## TIR Agent","metadata":{"papermill":{"duration":0.040506,"end_time":"2024-10-27T08:48:43.694998","exception":false,"start_time":"2024-10-27T08:48:43.654492","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# for row in test_df.values[7:8]:\n#     problem_id = row[0]\n#     problem = row[1]\n    \n#     agent = TIRAgent(problem_id, 0, problem, tokenizer, max_depth=4, log=None)\n    \n#     while not agent.complete():\n#         text = agent.next_message()\n#         # get response from LLM\n#         response = llm.generate([text], sampling_params)\n#         # pass in python executor, since response might contain python code\n#         agent.add_response(response[0].outputs[0].text, executor)\n    \n#     for message in agent.messages:\n#         print(f\"Role: {message['role']}\\n\")\n#         print(f\"Content:\\n {message['content']}\\n\")\n    \n#     answer = agent.final_answer()\n#     print(f\"Final answer: {answer}\")\n    ","metadata":{"papermill":{"duration":0.056414,"end_time":"2024-10-27T08:48:43.793136","exception":false,"start_time":"2024-10-27T08:48:43.736722","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:10:40.886728Z","iopub.execute_input":"2024-10-31T04:10:40.888527Z","iopub.status.idle":"2024-10-31T04:10:40.898771Z","shell.execute_reply.started":"2024-10-31T04:10:40.888419Z","shell.execute_reply":"2024-10-31T04:10:40.896090Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## SC-TIR Agent","metadata":{"papermill":{"duration":0.040801,"end_time":"2024-10-27T08:48:43.875226","exception":false,"start_time":"2024-10-27T08:48:43.834425","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# for row in test_df.values[88:89]:\n#     problem_id = row[0]\n#     problem = row[1]\n    \n#     agent = SCTIRAgent(problem_id, problem, tokenizer,samples=6, max_depth=6, log=None)\n    \n#     while not agent.complete():\n#         ready_agents = agent.get_ready_agents()\n#         texts = [a.next_message() for a in ready_agents]\n#         # get response from LLM\n#         responses = llm.generate(texts, sampling_params)\n#         # pass response to the agents\n#         for i, ready_agent in enumerate(ready_agents):\n#             ready_agent.add_response(responses[i].outputs[0].text, executor)\n    \n#     answer = agent.final_answer()\n#     print(f\"Problem: {problem}\")\n#     print(f\"Final answer: {answer}\")","metadata":{"papermill":{"duration":0.060047,"end_time":"2024-10-27T08:48:43.977176","exception":false,"start_time":"2024-10-27T08:48:43.917129","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:10:40.902500Z","iopub.execute_input":"2024-10-31T04:10:40.904376Z","iopub.status.idle":"2024-10-31T04:10:40.917170Z","shell.execute_reply.started":"2024-10-31T04:10:40.904222Z","shell.execute_reply":"2024-10-31T04:10:40.914232Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Run Inference","metadata":{"papermill":{"duration":0.041228,"end_time":"2024-10-27T08:48:44.0603","exception":false,"start_time":"2024-10-27T08:48:44.019072","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Create submission","metadata":{"papermill":{"duration":0.041752,"end_time":"2024-10-27T08:48:44.143431","exception":false,"start_time":"2024-10-27T08:48:44.101679","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Also log agent answers","metadata":{"papermill":{"duration":0.042114,"end_time":"2024-10-27T08:48:44.228821","exception":false,"start_time":"2024-10-27T08:48:44.186707","status":"completed"},"tags":[]}},{"cell_type":"code","source":"file = open('qwen32B.csv', 'w', encoding='utf-8')\nlog_file = open('log.csv', 'w', encoding='utf-8')\n\nsubmission = csv.writer(file)\nlog = csv.writer(log_file)\n\nsubmission.writerow(['ID', 'Answer'])\nlog.writerow(['ID', \"Agent ID\", 'Answer'])","metadata":{"papermill":{"duration":0.067379,"end_time":"2024-10-27T08:48:44.338641","exception":false,"start_time":"2024-10-27T08:48:44.271262","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:10:40.921051Z","iopub.execute_input":"2024-10-31T04:10:40.922460Z","iopub.status.idle":"2024-10-31T04:10:40.944109Z","shell.execute_reply.started":"2024-10-31T04:10:40.922356Z","shell.execute_reply":"2024-10-31T04:10:40.941990Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"20"},"metadata":{}}]},{"cell_type":"markdown","source":"## Configure LLM sampling parameters and Python REPL","metadata":{"papermill":{"duration":0.04182,"end_time":"2024-10-27T08:48:44.423726","exception":false,"start_time":"2024-10-27T08:48:44.381906","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Use a queue to Batch inference","metadata":{"papermill":{"duration":0.042338,"end_time":"2024-10-27T08:48:44.508026","exception":false,"start_time":"2024-10-27T08:48:44.465688","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%time\n\nboxed_answers = {}\nagents = []\n\nq = Queue()\n\niterator = iter(tqdm(test_df.values))\n\nwhile True:\n    for agent in agents:\n        if agent.complete():\n            agent_answer = agent.final_answer()\n            boxed_answers[agent.problem_id] = agent_answer\n            print(f'ID : {agent.problem_id}, Answer : {agent_answer}')\n\n    agents[:] = list(filter(lambda a: not a.complete(), agents))\n\n    while q.qsize() < BATCH_SIZE:\n        try:\n            row = next(iterator)\n        except StopIteration:\n            break\n\n        id = row[0]\n        problem = row[1]\n\n        agent = SCTIRAgent(id, problem, tokenizer, K, DEPTH, log)\n        \n        agents.append(agent)\n\n        for tir_agent in agent.get_ready_agents():\n            q.put_nowait(tir_agent)\n            \n    if q.empty():\n        break\n        \n    \n    ready_agents = []\n    texts = []\n    for _ in range(BATCH_SIZE):\n        try:\n            agent = q.get_nowait()\n            ready_agents.append(agent)\n            texts.append(agent.next_message())\n        except:\n            break\n\n    \n    responses = llm.generate(texts, sampling_params)\n    responses = [response.outputs[0].text for response in responses]\n    \n    for i in range(len(ready_agents)):\n        agent = ready_agents[i]\n        response = responses[i]\n        agent.add_response(response, executor)\n        if not agent.complete():\n            q.put_nowait(agent)\n   ","metadata":{"papermill":{"duration":24636.424417,"end_time":"2024-10-27T15:39:20.974382","exception":false,"start_time":"2024-10-27T08:48:44.549965","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-10-31T04:10:40.946324Z","iopub.execute_input":"2024-10-31T04:10:40.947234Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"  0%|          | 0/100 [00:00<?, ?it/s]\nProcessed prompts:   0%|          | 0/64 [00:00<?, ?it/s]\u001b[A\nProcessed prompts:   2%|▏         | 1/64 [02:01<2:07:25, 121.36s/it]\u001b[A\nProcessed prompts:   3%|▎         | 2/64 [02:10<57:07, 55.28s/it]   \u001b[A\nProcessed prompts:   5%|▍         | 3/64 [02:22<36:17, 35.70s/it]\u001b[A\nProcessed prompts:   6%|▋         | 4/64 [02:34<26:18, 26.31s/it]\u001b[A\nProcessed prompts:   8%|▊         | 5/64 [02:36<17:07, 17.41s/it]\u001b[A\nProcessed prompts:   9%|▉         | 6/64 [02:38<11:50, 12.24s/it]\u001b[A\nProcessed prompts:  11%|█         | 7/64 [02:42<08:59,  9.47s/it]\u001b[A\nProcessed prompts:  12%|█▎        | 8/64 [02:42<06:10,  6.61s/it]\u001b[A\nProcessed prompts:  14%|█▍        | 9/64 [02:45<04:50,  5.27s/it]\u001b[A\nProcessed prompts:  16%|█▌        | 10/64 [02:47<03:49,  4.26s/it]\u001b[A\nProcessed prompts:  17%|█▋        | 11/64 [02:52<03:57,  4.48s/it]\u001b[A\nProcessed prompts:  19%|█▉        | 12/64 [02:54<03:23,  3.92s/it]\u001b[A\nProcessed prompts:  20%|██        | 13/64 [02:58<03:10,  3.73s/it]\u001b[A\nProcessed prompts:  22%|██▏       | 14/64 [02:58<02:20,  2.81s/it]\u001b[A\nProcessed prompts:  23%|██▎       | 15/64 [03:03<02:41,  3.29s/it]\u001b[A\nProcessed prompts:  25%|██▌       | 16/64 [03:05<02:27,  3.08s/it]\u001b[A\nProcessed prompts:  27%|██▋       | 17/64 [03:11<03:00,  3.84s/it]\u001b[A\nProcessed prompts:  28%|██▊       | 18/64 [03:15<03:03,  3.98s/it]\u001b[A\nProcessed prompts:  30%|██▉       | 19/64 [03:17<02:37,  3.50s/it]\u001b[A\nProcessed prompts:  33%|███▎      | 21/64 [03:21<01:59,  2.79s/it]\u001b[A\nProcessed prompts:  34%|███▍      | 22/64 [03:28<02:36,  3.73s/it]\u001b[A\nProcessed prompts:  36%|███▌      | 23/64 [03:30<02:09,  3.15s/it]\u001b[A\nProcessed prompts:  38%|███▊      | 24/64 [03:40<03:25,  5.13s/it]\u001b[A\nProcessed prompts:  39%|███▉      | 25/64 [03:43<02:56,  4.52s/it]\u001b[A\nProcessed prompts:  41%|████      | 26/64 [03:45<02:25,  3.82s/it]\u001b[A\nProcessed prompts:  42%|████▏     | 27/64 [03:54<03:18,  5.35s/it]\u001b[A\nProcessed prompts:  44%|████▍     | 28/64 [03:56<02:39,  4.44s/it]\u001b[A\nProcessed prompts:  45%|████▌     | 29/64 [03:59<02:12,  3.79s/it]\u001b[A\nProcessed prompts:  47%|████▋     | 30/64 [04:03<02:18,  4.07s/it]\u001b[A\nProcessed prompts:  48%|████▊     | 31/64 [04:11<02:49,  5.14s/it]\u001b[A\nProcessed prompts:  50%|█████     | 32/64 [04:15<02:30,  4.71s/it]\u001b[A\nProcessed prompts:  52%|█████▏    | 33/64 [04:15<01:48,  3.51s/it]\u001b[A\nProcessed prompts:  53%|█████▎    | 34/64 [04:23<02:24,  4.83s/it]\u001b[A\nProcessed prompts:  55%|█████▍    | 35/64 [04:26<02:06,  4.35s/it]\u001b[A\nProcessed prompts:  56%|█████▋    | 36/64 [04:32<02:15,  4.83s/it]\u001b[A\nProcessed prompts:  58%|█████▊    | 37/64 [04:33<01:34,  3.52s/it]\u001b[A\nProcessed prompts:  59%|█████▉    | 38/64 [04:40<01:59,  4.61s/it]\u001b[A\nProcessed prompts:  61%|██████    | 39/64 [04:41<01:27,  3.50s/it]\u001b[A\nProcessed prompts:  62%|██████▎   | 40/64 [04:45<01:24,  3.52s/it]\u001b[A\nProcessed prompts:  64%|██████▍   | 41/64 [04:47<01:16,  3.34s/it]\u001b[A\nProcessed prompts:  66%|██████▌   | 42/64 [04:52<01:23,  3.78s/it]\u001b[A\nProcessed prompts:  67%|██████▋   | 43/64 [04:54<01:07,  3.23s/it]\u001b[A\nProcessed prompts:  69%|██████▉   | 44/64 [04:57<01:00,  3.04s/it]\u001b[A\nProcessed prompts:  70%|███████   | 45/64 [04:59<00:51,  2.71s/it]\u001b[A\nProcessed prompts:  72%|███████▏  | 46/64 [04:59<00:36,  2.02s/it]\u001b[A\nProcessed prompts:  73%|███████▎  | 47/64 [05:05<00:52,  3.08s/it]\u001b[A\nProcessed prompts:  75%|███████▌  | 48/64 [05:05<00:35,  2.22s/it]\u001b[A\nProcessed prompts:  77%|███████▋  | 49/64 [05:11<00:48,  3.25s/it]\u001b[A\nProcessed prompts:  78%|███████▊  | 50/64 [05:15<00:49,  3.52s/it]\u001b[A\nProcessed prompts:  80%|███████▉  | 51/64 [05:15<00:33,  2.58s/it]\u001b[A\nProcessed prompts:  81%|████████▏ | 52/64 [05:17<00:28,  2.34s/it]\u001b[A\nProcessed prompts:  83%|████████▎ | 53/64 [05:18<00:20,  1.85s/it]\u001b[A\nProcessed prompts:  84%|████████▍ | 54/64 [05:20<00:19,  1.98s/it]\u001b[A\nProcessed prompts:  86%|████████▌ | 55/64 [05:22<00:18,  2.05s/it]\u001b[A\nProcessed prompts:  88%|████████▊ | 56/64 [05:25<00:17,  2.21s/it]\u001b[A\nProcessed prompts:  89%|████████▉ | 57/64 [05:26<00:13,  1.93s/it]\u001b[A\nProcessed prompts:  91%|█████████ | 58/64 [05:32<00:19,  3.23s/it]\u001b[A\nProcessed prompts:  94%|█████████▍| 60/64 [05:39<00:13,  3.34s/it]\u001b[A\nProcessed prompts:  95%|█████████▌| 61/64 [05:42<00:09,  3.26s/it]\u001b[A\nProcessed prompts:  97%|█████████▋| 62/64 [05:42<00:04,  2.46s/it]\u001b[A\nProcessed prompts:  98%|█████████▊| 63/64 [05:46<00:02,  2.89s/it]\u001b[A\nProcessed prompts: 100%|██████████| 64/64 [07:03<00:00,  6.61s/it]\u001b[A\n\nProcessed prompts:   0%|          | 0/64 [00:00<?, ?it/s]\u001b[A\nProcessed prompts:   2%|▏         | 1/64 [01:30<1:35:25, 90.89s/it]\u001b[A\nProcessed prompts:   3%|▎         | 2/64 [01:33<40:01, 38.74s/it]  \u001b[A\nProcessed prompts:   5%|▍         | 3/64 [01:37<23:20, 22.96s/it]\u001b[A\nProcessed prompts:   6%|▋         | 4/64 [01:37<13:59, 13.99s/it]\u001b[A\nProcessed prompts:   8%|▊         | 5/64 [01:45<11:47, 11.99s/it]\u001b[A\nProcessed prompts:   9%|▉         | 6/64 [01:51<09:31,  9.85s/it]\u001b[A\nProcessed prompts:  11%|█         | 7/64 [02:02<09:40, 10.19s/it]\u001b[A\nProcessed prompts:  12%|█▎        | 8/64 [02:07<07:55,  8.50s/it]\u001b[A\nProcessed prompts:  14%|█▍        | 9/64 [02:09<05:51,  6.38s/it]\u001b[A\nProcessed prompts:  16%|█▌        | 10/64 [02:15<05:35,  6.22s/it]\u001b[A\nProcessed prompts:  19%|█▉        | 12/64 [02:26<05:11,  5.98s/it]\u001b[A\nProcessed prompts:  20%|██        | 13/64 [02:29<04:26,  5.22s/it]\u001b[A\nProcessed prompts:  22%|██▏       | 14/64 [02:34<04:13,  5.08s/it]\u001b[A\nProcessed prompts:  23%|██▎       | 15/64 [02:38<04:01,  4.93s/it]\u001b[A\nProcessed prompts:  25%|██▌       | 16/64 [02:45<04:20,  5.44s/it]\u001b[A\nProcessed prompts:  27%|██▋       | 17/64 [02:47<03:34,  4.57s/it]\u001b[A\nProcessed prompts:  28%|██▊       | 18/64 [03:00<05:16,  6.87s/it]\u001b[A\nProcessed prompts:  30%|██▉       | 19/64 [03:02<04:07,  5.50s/it]\u001b[A\nProcessed prompts:  31%|███▏      | 20/64 [03:05<03:25,  4.67s/it]\u001b[A\nProcessed prompts:  33%|███▎      | 21/64 [03:15<04:28,  6.24s/it]\u001b[A\nProcessed prompts:  34%|███▍      | 22/64 [03:19<03:53,  5.55s/it]\u001b[A\nProcessed prompts:  36%|███▌      | 23/64 [03:21<03:12,  4.69s/it]\u001b[A\nProcessed prompts:  38%|███▊      | 24/64 [03:22<02:18,  3.47s/it]\u001b[A\nProcessed prompts:  39%|███▉      | 25/64 [03:28<02:47,  4.29s/it]\u001b[A\nProcessed prompts:  41%|████      | 26/64 [03:31<02:33,  4.04s/it]\u001b[A\nProcessed prompts:  44%|████▍     | 28/64 [03:43<02:51,  4.75s/it]\u001b[A\nProcessed prompts:  45%|████▌     | 29/64 [03:43<02:07,  3.63s/it]\u001b[A\nProcessed prompts:  47%|████▋     | 30/64 [03:47<02:06,  3.73s/it]\u001b[A\nProcessed prompts:  48%|████▊     | 31/64 [03:53<02:26,  4.45s/it]\u001b[A\nProcessed prompts:  50%|█████     | 32/64 [03:59<02:35,  4.87s/it]\u001b[A\nProcessed prompts:  52%|█████▏    | 33/64 [04:00<01:53,  3.67s/it]\u001b[A\nProcessed prompts:  55%|█████▍    | 35/64 [04:06<01:40,  3.48s/it]\u001b[A\nProcessed prompts:  56%|█████▋    | 36/64 [04:09<01:32,  3.29s/it]\u001b[A\nProcessed prompts:  58%|█████▊    | 37/64 [04:12<01:27,  3.23s/it]\u001b[A\nProcessed prompts:  59%|█████▉    | 38/64 [04:16<01:25,  3.27s/it]\u001b[A\nProcessed prompts:  61%|██████    | 39/64 [04:19<01:22,  3.28s/it]\u001b[A\nProcessed prompts:  62%|██████▎   | 40/64 [04:29<02:07,  5.31s/it]\u001b[A\nProcessed prompts:  64%|██████▍   | 41/64 [04:40<02:38,  6.88s/it]\u001b[A\nProcessed prompts:  66%|██████▌   | 42/64 [04:50<02:50,  7.76s/it]\u001b[A\nProcessed prompts:  67%|██████▋   | 43/64 [04:57<02:38,  7.53s/it]\u001b[A\nProcessed prompts:  69%|██████▉   | 44/64 [05:09<02:58,  8.93s/it]\u001b[A\nProcessed prompts:  70%|███████   | 45/64 [05:16<02:35,  8.18s/it]\u001b[A\nProcessed prompts:  72%|███████▏  | 46/64 [05:21<02:10,  7.25s/it]\u001b[A\nProcessed prompts:  73%|███████▎  | 47/64 [05:29<02:08,  7.54s/it]\u001b[A\nProcessed prompts:  75%|███████▌  | 48/64 [05:34<01:49,  6.84s/it]\u001b[A\nProcessed prompts:  77%|███████▋  | 49/64 [05:44<01:55,  7.69s/it]\u001b[A\nProcessed prompts:  78%|███████▊  | 50/64 [05:49<01:35,  6.84s/it]\u001b[A\nProcessed prompts:  80%|███████▉  | 51/64 [05:50<01:09,  5.38s/it]\u001b[A\nProcessed prompts:  81%|████████▏ | 52/64 [05:51<00:47,  3.99s/it]\u001b[A\nProcessed prompts:  83%|████████▎ | 53/64 [05:55<00:44,  4.07s/it]\u001b[A\nProcessed prompts:  84%|████████▍ | 54/64 [05:57<00:34,  3.40s/it]\u001b[A\nProcessed prompts:  86%|████████▌ | 55/64 [06:08<00:49,  5.54s/it]\u001b[A\nProcessed prompts:  88%|████████▊ | 56/64 [06:11<00:38,  4.78s/it]\u001b[A\nProcessed prompts:  89%|████████▉ | 57/64 [06:11<00:24,  3.48s/it]\u001b[A\nProcessed prompts:  91%|█████████ | 58/64 [06:13<00:17,  2.99s/it]\u001b[A\nProcessed prompts:  92%|█████████▏| 59/64 [06:14<00:11,  2.27s/it]\u001b[A\nProcessed prompts:  95%|█████████▌| 61/64 [06:18<00:06,  2.11s/it]\u001b[A\nProcessed prompts:  97%|█████████▋| 62/64 [06:19<00:03,  1.95s/it]\u001b[A\nProcessed prompts:  98%|█████████▊| 63/64 [06:21<00:01,  1.83s/it]\u001b[A\nProcessed prompts: 100%|██████████| 64/64 [06:36<00:00,  6.19s/it]\u001b[A\n\nProcessed prompts:   0%|          | 0/64 [00:00<?, ?it/s]\u001b[A\nProcessed prompts:   2%|▏         | 1/64 [00:48<51:07, 48.70s/it]\u001b[A\nProcessed prompts:   3%|▎         | 2/64 [00:49<21:20, 20.66s/it]\u001b[A\nProcessed prompts:   5%|▍         | 3/64 [01:03<17:36, 17.32s/it]\u001b[A\nProcessed prompts:   6%|▋         | 4/64 [01:29<20:53, 20.90s/it]\u001b[A\nProcessed prompts:   8%|▊         | 5/64 [01:33<14:29, 14.74s/it]\u001b[A\nProcessed prompts:   9%|▉         | 6/64 [01:36<10:21, 10.71s/it]\u001b[A\nProcessed prompts:  11%|█         | 7/64 [01:41<08:39,  9.11s/it]\u001b[A\nProcessed prompts:  12%|█▎        | 8/64 [01:46<07:05,  7.60s/it]\u001b[A\nProcessed prompts:  14%|█▍        | 9/64 [01:50<06:00,  6.55s/it]\u001b[A\nProcessed prompts:  16%|█▌        | 10/64 [01:53<04:49,  5.36s/it]\u001b[A\nProcessed prompts:  17%|█▋        | 11/64 [01:56<04:15,  4.82s/it]\u001b[A\nProcessed prompts:  19%|█▉        | 12/64 [02:00<03:57,  4.57s/it]\u001b[A\nProcessed prompts:  20%|██        | 13/64 [02:02<03:10,  3.73s/it]\u001b[A\nProcessed prompts:  22%|██▏       | 14/64 [02:06<03:13,  3.87s/it]\u001b[A\nProcessed prompts:  23%|██▎       | 15/64 [02:11<03:14,  3.98s/it]\u001b[A\nProcessed prompts:  25%|██▌       | 16/64 [02:11<02:17,  2.85s/it]\u001b[A\nProcessed prompts:  27%|██▋       | 17/64 [02:15<02:28,  3.16s/it]\u001b[A\nProcessed prompts:  28%|██▊       | 18/64 [02:19<02:35,  3.37s/it]\u001b[A\nProcessed prompts:  30%|██▉       | 19/64 [02:25<03:14,  4.32s/it]\u001b[A\nProcessed prompts:  31%|███▏      | 20/64 [02:28<02:57,  4.04s/it]\u001b[A\nProcessed prompts:  33%|███▎      | 21/64 [02:30<02:25,  3.38s/it]\u001b[A\nProcessed prompts:  34%|███▍      | 22/64 [02:34<02:25,  3.46s/it]\u001b[A\nProcessed prompts:  36%|███▌      | 23/64 [02:37<02:19,  3.40s/it]\u001b[A\nProcessed prompts:  38%|███▊      | 24/64 [02:41<02:23,  3.58s/it]\u001b[A\nProcessed prompts:  39%|███▉      | 25/64 [02:47<02:40,  4.11s/it]\u001b[A\nProcessed prompts:  41%|████      | 26/64 [02:51<02:35,  4.10s/it]\u001b[A\nProcessed prompts:  42%|████▏     | 27/64 [02:55<02:36,  4.22s/it]\u001b[A\nProcessed prompts:  44%|████▍     | 28/64 [02:58<02:19,  3.87s/it]\u001b[A\nProcessed prompts:  45%|████▌     | 29/64 [03:03<02:21,  4.05s/it]\u001b[A\nProcessed prompts:  47%|████▋     | 30/64 [03:06<02:07,  3.76s/it]\u001b[A\nProcessed prompts:  48%|████▊     | 31/64 [03:09<02:02,  3.71s/it]\u001b[A\nProcessed prompts:  50%|█████     | 32/64 [03:13<02:00,  3.76s/it]\u001b[A\nProcessed prompts:  52%|█████▏    | 33/64 [03:16<01:44,  3.38s/it]\u001b[A\nProcessed prompts:  53%|█████▎    | 34/64 [03:21<01:55,  3.85s/it]\u001b[A\nProcessed prompts:  55%|█████▍    | 35/64 [03:25<01:54,  3.94s/it]\u001b[A\nProcessed prompts:  56%|█████▋    | 36/64 [03:28<01:40,  3.57s/it]\u001b[A\nProcessed prompts:  58%|█████▊    | 37/64 [03:32<01:45,  3.90s/it]\u001b[A\nProcessed prompts:  59%|█████▉    | 38/64 [03:33<01:13,  2.84s/it]\u001b[A\nProcessed prompts:  61%|██████    | 39/64 [03:37<01:22,  3.31s/it]\u001b[A\nProcessed prompts:  62%|██████▎   | 40/64 [03:38<01:03,  2.64s/it]\u001b[A\nProcessed prompts:  64%|██████▍   | 41/64 [03:43<01:17,  3.35s/it]\u001b[A\nProcessed prompts:  66%|██████▌   | 42/64 [03:47<01:15,  3.43s/it]\u001b[A\nProcessed prompts:  67%|██████▋   | 43/64 [03:53<01:31,  4.37s/it]\u001b[A\nProcessed prompts:  69%|██████▉   | 44/64 [04:00<01:43,  5.18s/it]\u001b[A\nProcessed prompts:  70%|███████   | 45/64 [04:03<01:26,  4.53s/it]\u001b[A\nProcessed prompts:  72%|███████▏  | 46/64 [04:11<01:37,  5.40s/it]\u001b[A\nProcessed prompts:  73%|███████▎  | 47/64 [04:16<01:30,  5.34s/it]\u001b[A\nProcessed prompts:  75%|███████▌  | 48/64 [04:26<01:49,  6.82s/it]\u001b[A\nProcessed prompts:  77%|███████▋  | 49/64 [04:35<01:51,  7.42s/it]\u001b[A\nProcessed prompts:  78%|███████▊  | 50/64 [04:42<01:44,  7.43s/it]\u001b[A\nProcessed prompts:  80%|███████▉  | 51/64 [04:46<01:23,  6.40s/it]\u001b[A\nProcessed prompts:  81%|████████▏ | 52/64 [05:06<02:05, 10.48s/it]\u001b[A\nProcessed prompts:  83%|████████▎ | 53/64 [05:16<01:51, 10.15s/it]\u001b[A\nProcessed prompts:  84%|████████▍ | 54/64 [05:24<01:35,  9.57s/it]\u001b[A\nProcessed prompts:  86%|████████▌ | 55/64 [05:36<01:33, 10.38s/it]\u001b[A\nProcessed prompts:  88%|████████▊ | 56/64 [05:49<01:28, 11.05s/it]\u001b[A\nProcessed prompts:  89%|████████▉ | 57/64 [05:54<01:04,  9.20s/it]\u001b[A\nProcessed prompts:  91%|█████████ | 58/64 [06:00<00:49,  8.29s/it]\u001b[A\nProcessed prompts:  92%|█████████▏| 59/64 [06:06<00:37,  7.58s/it]\u001b[A\nProcessed prompts:  94%|█████████▍| 60/64 [06:19<00:36,  9.18s/it]\u001b[A\nProcessed prompts:  95%|█████████▌| 61/64 [06:23<00:22,  7.58s/it]\u001b[A\nProcessed prompts:  97%|█████████▋| 62/64 [06:25<00:11,  5.98s/it]\u001b[A\nProcessed prompts:  98%|█████████▊| 63/64 [06:35<00:07,  7.09s/it]\u001b[A\nProcessed prompts: 100%|██████████| 64/64 [06:46<00:00,  6.35s/it]\u001b[A\n  6%|▌         | 6/100 [21:54<5:43:20, 219.16s/it]","output_type":"stream"},{"name":"stdout","text":"ID : 0, Answer : 4\nID : 1, Answer : 10\nID : 2, Answer : 3\nID : 3, Answer : 2023\n","output_type":"stream"},{"name":"stderr","text":"\nProcessed prompts:   0%|          | 0/64 [00:00<?, ?it/s]\u001b[A\nProcessed prompts:   2%|▏         | 1/64 [00:48<50:58, 48.54s/it]\u001b[A\nProcessed prompts:   3%|▎         | 2/64 [00:52<22:54, 22.17s/it]\u001b[A\nProcessed prompts:   5%|▍         | 3/64 [00:55<13:59, 13.76s/it]\u001b[A\nProcessed prompts:   6%|▋         | 4/64 [00:56<08:28,  8.47s/it]\u001b[A\nProcessed prompts:   8%|▊         | 5/64 [01:00<06:57,  7.08s/it]\u001b[A\nProcessed prompts:   9%|▉         | 6/64 [01:05<05:51,  6.07s/it]\u001b[A\nProcessed prompts:  11%|█         | 7/64 [01:09<05:16,  5.56s/it]\u001b[A\nProcessed prompts:  12%|█▎        | 8/64 [01:13<04:39,  4.99s/it]\u001b[A\nProcessed prompts:  16%|█▌        | 10/64 [01:17<03:08,  3.50s/it]\u001b[A\nProcessed prompts:  17%|█▋        | 11/64 [01:23<03:45,  4.25s/it]\u001b[A\nProcessed prompts:  19%|█▉        | 12/64 [01:32<04:49,  5.56s/it]\u001b[A\nProcessed prompts:  20%|██        | 13/64 [01:40<05:20,  6.28s/it]\u001b[A\nProcessed prompts:  22%|██▏       | 14/64 [01:43<04:21,  5.23s/it]\u001b[A\nProcessed prompts:  23%|██▎       | 15/64 [01:49<04:30,  5.53s/it]\u001b[A\nProcessed prompts:  25%|██▌       | 16/64 [01:55<04:27,  5.58s/it]\u001b[A\nProcessed prompts:  27%|██▋       | 17/64 [02:17<08:13, 10.49s/it]\u001b[A\nProcessed prompts:  28%|██▊       | 18/64 [02:30<08:33, 11.15s/it]\u001b[A\nProcessed prompts:  30%|██▉       | 19/64 [02:59<12:24, 16.53s/it]\u001b[A\nProcessed prompts:  31%|███▏      | 20/64 [03:10<10:47, 14.71s/it]\u001b[A\nProcessed prompts:  33%|███▎      | 21/64 [03:35<12:52, 17.96s/it]\u001b[A\nProcessed prompts:  34%|███▍      | 22/64 [03:43<10:29, 15.00s/it]\u001b[A\nProcessed prompts:  36%|███▌      | 23/64 [04:12<12:58, 18.98s/it]\u001b[A\nProcessed prompts:  38%|███▊      | 24/64 [04:15<09:35, 14.40s/it]\u001b[A\nProcessed prompts:  39%|███▉      | 25/64 [04:24<08:17, 12.75s/it]\u001b[A\nProcessed prompts:  41%|████      | 26/64 [04:29<06:39, 10.50s/it]\u001b[A\nProcessed prompts:  42%|████▏     | 27/64 [04:32<05:01,  8.15s/it]\u001b[A\nProcessed prompts:  44%|████▍     | 28/64 [04:36<04:09,  6.94s/it]\u001b[A\nProcessed prompts:  45%|████▌     | 29/64 [04:50<05:12,  8.93s/it]\u001b[A\nProcessed prompts:  47%|████▋     | 30/64 [04:55<04:24,  7.79s/it]\u001b[A\nProcessed prompts:  48%|████▊     | 31/64 [05:16<06:29, 11.80s/it]\u001b[A\nProcessed prompts:  50%|█████     | 32/64 [05:31<06:45, 12.68s/it]\u001b[A\nProcessed prompts:  52%|█████▏    | 33/64 [05:41<06:12, 12.02s/it]\u001b[A\nProcessed prompts:  53%|█████▎    | 34/64 [05:47<05:05, 10.18s/it]\u001b[A\nProcessed prompts:  55%|█████▍    | 35/64 [05:52<04:08,  8.58s/it]\u001b[A\nProcessed prompts:  58%|█████▊    | 37/64 [06:01<02:59,  6.64s/it]\u001b[A\nProcessed prompts:  59%|█████▉    | 38/64 [06:05<02:36,  6.03s/it]\u001b[A\nProcessed prompts:  61%|██████    | 39/64 [06:08<02:08,  5.14s/it]\u001b[A\nProcessed prompts:  62%|██████▎   | 40/64 [06:12<01:58,  4.95s/it]\u001b[A\nProcessed prompts:  64%|██████▍   | 41/64 [06:15<01:43,  4.50s/it]\u001b[A\nProcessed prompts:  66%|██████▌   | 42/64 [06:21<01:48,  4.92s/it]\u001b[A\nProcessed prompts:  67%|██████▋   | 43/64 [06:25<01:33,  4.45s/it]\u001b[A\nProcessed prompts:  69%|██████▉   | 44/64 [06:26<01:11,  3.59s/it]\u001b[A\nProcessed prompts:  70%|███████   | 45/64 [06:28<00:58,  3.10s/it]\u001b[A\nProcessed prompts:  72%|███████▏  | 46/64 [06:33<01:04,  3.56s/it]\u001b[A\nProcessed prompts:  73%|███████▎  | 47/64 [06:36<01:01,  3.62s/it]\u001b[A\nProcessed prompts:  75%|███████▌  | 48/64 [06:41<01:04,  4.02s/it]\u001b[A\nProcessed prompts:  77%|███████▋  | 49/64 [06:50<01:20,  5.37s/it]\u001b[A\nProcessed prompts:  78%|███████▊  | 50/64 [06:51<00:57,  4.10s/it]\u001b[A\nProcessed prompts:  80%|███████▉  | 51/64 [07:06<01:35,  7.37s/it]\u001b[A\nProcessed prompts:  81%|████████▏ | 52/64 [07:09<01:11,  6.00s/it]\u001b[A\nProcessed prompts:  83%|████████▎ | 53/64 [07:12<00:56,  5.10s/it]\u001b[A\nProcessed prompts:  84%|████████▍ | 54/64 [07:12<00:37,  3.71s/it]\u001b[A\nProcessed prompts:  86%|████████▌ | 55/64 [07:20<00:45,  5.02s/it]\u001b[A\nProcessed prompts:  88%|████████▊ | 56/64 [07:23<00:33,  4.24s/it]\u001b[A\nProcessed prompts:  89%|████████▉ | 57/64 [07:25<00:25,  3.67s/it]\u001b[A\nProcessed prompts:  91%|█████████ | 58/64 [07:27<00:18,  3.13s/it]\u001b[A\nProcessed prompts:  92%|█████████▏| 59/64 [07:29<00:13,  2.68s/it]\u001b[A\nProcessed prompts:  94%|█████████▍| 60/64 [07:36<00:16,  4.21s/it]\u001b[A\nProcessed prompts:  95%|█████████▌| 61/64 [07:40<00:12,  4.13s/it]\u001b[A\nProcessed prompts:  97%|█████████▋| 62/64 [07:42<00:06,  3.36s/it]\u001b[A\nProcessed prompts:  98%|█████████▊| 63/64 [07:46<00:03,  3.62s/it]\u001b[A\nProcessed prompts: 100%|██████████| 64/64 [07:49<00:00,  7.34s/it]\u001b[A\n 10%|█         | 10/100 [30:15<4:19:51, 173.24s/it]","output_type":"stream"},{"name":"stdout","text":"ID : 4, Answer : 1023\nID : 5, Answer : 0\n","output_type":"stream"},{"name":"stderr","text":"\nProcessed prompts:   0%|          | 0/64 [00:00<?, ?it/s]\u001b[A\nProcessed prompts:   2%|▏         | 1/64 [01:16<1:20:35, 76.75s/it]\u001b[A\nProcessed prompts:   3%|▎         | 2/64 [01:45<50:20, 48.72s/it]  \u001b[A\nProcessed prompts:   5%|▍         | 3/64 [01:51<29:37, 29.14s/it]\u001b[A\nProcessed prompts:   6%|▋         | 4/64 [01:55<19:01, 19.03s/it]\u001b[A","output_type":"stream"}]},{"cell_type":"markdown","source":"## Write to submission file","metadata":{"papermill":{"duration":1.240793,"end_time":"2024-10-27T15:39:23.416519","exception":false,"start_time":"2024-10-27T15:39:22.175726","status":"completed"},"tags":[]}},{"cell_type":"code","source":"for id, answer in boxed_answers.items():\n    submission.writerow([id, answer])","metadata":{"papermill":{"duration":1.218836,"end_time":"2024-10-27T15:39:25.871198","exception":false,"start_time":"2024-10-27T15:39:24.652362","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Close files","metadata":{"papermill":{"duration":1.260956,"end_time":"2024-10-27T15:39:28.450512","exception":false,"start_time":"2024-10-27T15:39:27.189556","status":"completed"},"tags":[]}},{"cell_type":"code","source":"   \nfile.close()\nlog_file.close()","metadata":{"papermill":{"duration":1.279719,"end_time":"2024-10-27T15:39:30.923315","exception":false,"start_time":"2024-10-27T15:39:29.643596","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Combined Prompts inference","metadata":{"papermill":{"duration":1.193926,"end_time":"2024-10-27T15:39:33.363845","exception":false,"start_time":"2024-10-27T15:39:32.169919","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# import pandas as pd\n# import torch\n\n# # Load the CSV file with problems and prompts\n# df = pd.read_csv(\"/kaggle/input/dlsprint3/test.csv\")\n\n# # Specify the ID of the test problem (change as needed)\n# test_id = 7  # Example test case ID\n# test_problem = df.loc[test_id, 'Problem']\n# #similar_problems_solutions = df.loc[test_id, 'prompts']  # Get the related problems and solutions\n# print(test_problem)\n\n# # Create the prompt for the model\n# prompt = f\"\"\"Here is a math problem in Bengali:\n# {test_problem}. Here is a problem.)\n# The answer is a non-negative integer. Please reason step by step to solve the problem above. \n# Put your final integer answer within \\\\boxed{{}}.\"\"\"\n\n# prompts = [{\"role\": \"system\", \"content\": \"You are a helpful math assistant.\"},{\"role\": \"user\", \"content\": prompt}]\n\n# # Tokenize the input prompt\n# tokens = tokenizer.apply_chat_template(\n#             prompts,\n#             tokenize=False,\n#             add_generation_prompt=True\n#         )\n\n# # Generate the solution using the model\n# generated_solution = llm.generate(tokens,sampling_params)\n\n# # Output the generated solution\n# print(f\"Generated solution for test problem {test_id}:\")\n# print(generated_solution[0].outputs[0].text)\n","metadata":{"papermill":{"duration":1.261874,"end_time":"2024-10-27T15:39:35.865185","exception":false,"start_time":"2024-10-27T15:39:34.603311","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pandas as pd\n\n# # Load the CSV file\n# df = pd.read_csv(\"pruned_prompts.csv\")\n\n# # Define a function to prune the 5th problem and its solution from each 'prompts' entry\n# def prune_fifth_problem(prompts_text):\n#     # Split the prompts into individual problems/solutions\n#     problems = prompts_text.split(\"Problem:\")\n    \n#     # Check if there are at least 5 problems\n#     if len(problems) > 2:\n#         # Remove the 5th problem (index 5 is actually the 6th element, as index starts from 0)\n#         del problems[2]\n        \n#     # Rejoin the remaining problems and solutions\n#     return \"Problem:\".join(problems)\n\n# # Apply the function to the 'prompts' column\n# df['prompts'] = df['prompts'].apply(prune_fifth_problem)\n\n# # Now the 'pruned_prompts' column contains the updated text with the 5th problem removed\n# print(df[['ID', 'prompts']].head())  # Display the updated prompts for the first few rows\n\n# # You can save the updated DataFrame to a new CSV if needed\n# # df.to_csv(\"pruned_prompts.csv\", index=False)\n","metadata":{"papermill":{"duration":1.252765,"end_time":"2024-10-27T15:39:38.317339","exception":false,"start_time":"2024-10-27T15:39:37.064574","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df.to_csv(\"pruned_prompts.csv\", index=False)","metadata":{"papermill":{"duration":1.222889,"end_time":"2024-10-27T15:39:40.783831","exception":false,"start_time":"2024-10-27T15:39:39.560942","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df['prompts'] = df['prompts'].str.replace(\"Here are a list of math problems and solutions:\", \"\", regex=False)\n\n# # Display the updated DataFrame to confirm the string has been removed\n# print(df.head())","metadata":{"papermill":{"duration":1.24791,"end_time":"2024-10-27T15:39:43.271916","exception":false,"start_time":"2024-10-27T15:39:42.024006","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df.to_csv(\"pruned_prompts.csv\", index=False)","metadata":{"papermill":{"duration":1.244364,"end_time":"2024-10-27T15:39:45.719389","exception":false,"start_time":"2024-10-27T15:39:44.475025","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":1.191967,"end_time":"2024-10-27T15:39:48.168458","exception":false,"start_time":"2024-10-27T15:39:46.976491","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}