{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":86200,"databundleVersionId":9773555,"sourceType":"competition"}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-10-15T13:53:40.471252Z","iopub.execute_input":"2024-10-15T13:53:40.471973Z","iopub.status.idle":"2024-10-15T13:53:40.476226Z","shell.execute_reply.started":"2024-10-15T13:53:40.471930Z","shell.execute_reply":"2024-10-15T13:53:40.475217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"TRNSLATION","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n\n# Load the pre-trained translation model and tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"shihab17/bengali-bn-to-en\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"shihab17/bengali-bn-to-en\")","metadata":{"execution":{"iopub.status.busy":"2024-10-15T13:53:43.068338Z","iopub.execute_input":"2024-10-15T13:53:43.068727Z","iopub.status.idle":"2024-10-15T13:53:47.007990Z","shell.execute_reply.started":"2024-10-15T13:53:43.068688Z","shell.execute_reply":"2024-10-15T13:53:47.006993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check if GPU is available\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n# Move the model to the appropriate device (GPU if available, otherwise CPU)\nmodel = model.to(device)\n\ndef translator(sentence):\n    # Tokenize the input sentence and move it to the appropriate device\n    inputs = tokenizer.encode(sentence, return_tensors=\"pt\").to(device)\n\n    # Get the translation using the model (which runs on GPU if available)\n    translated = model.generate(inputs)\n\n    # Decode the translation into a readable format\n    translated_sentence = tokenizer.decode(translated[0], skip_special_tokens=True)\n\n    return translated_sentence","metadata":{"execution":{"iopub.status.busy":"2024-10-15T13:53:47.009983Z","iopub.execute_input":"2024-10-15T13:53:47.010369Z","iopub.status.idle":"2024-10-15T13:53:47.395977Z","shell.execute_reply.started":"2024-10-15T13:53:47.010326Z","shell.execute_reply":"2024-10-15T13:53:47.394990Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LOAD & PROCESS DATA","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/dlsprint3/test.csv')\ntrain_df = pd.read_csv('/kaggle/input/dlsprint3/train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-10-15T13:53:49.795010Z","iopub.execute_input":"2024-10-15T13:53:49.795392Z","iopub.status.idle":"2024-10-15T13:53:49.824111Z","shell.execute_reply.started":"2024-10-15T13:53:49.795356Z","shell.execute_reply":"2024-10-15T13:53:49.823193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the translator function to the 'Problem' column\ntest_df['Translated_Problem'] = test_df['Problem'].apply(translator)\n\nprint(test_df['Translated_Problem'])","metadata":{"execution":{"iopub.status.busy":"2024-10-15T13:53:52.023560Z","iopub.execute_input":"2024-10-15T13:53:52.023972Z","iopub.status.idle":"2024-10-15T13:55:09.733641Z","shell.execute_reply.started":"2024-10-15T13:53:52.023933Z","shell.execute_reply":"2024-10-15T13:55:09.732747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test_df['Translated_Problem'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"NUMINA MODEL","metadata":{}},{"cell_type":"code","source":"import re\nimport torch\nfrom transformers import pipeline\nimport io\nimport sys\n","metadata":{"execution":{"iopub.status.busy":"2024-10-15T13:58:34.911655Z","iopub.execute_input":"2024-10-15T13:58:34.912566Z","iopub.status.idle":"2024-10-15T13:58:49.621718Z","shell.execute_reply.started":"2024-10-15T13:58:34.912516Z","shell.execute_reply":"2024-10-15T13:58:49.620909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"PROMPT ENGINNERING","metadata":{}},{"cell_type":"code","source":"# Initialize the pipeline\npipe = pipeline(\"text-generation\", model=\"AI-MO/NuminaMath-7B-TIR\", torch_dtype=torch.bfloat16, device_map=\"auto\")","metadata":{"execution":{"iopub.status.busy":"2024-10-15T14:08:11.378267Z","iopub.execute_input":"2024-10-15T14:08:11.379030Z","iopub.status.idle":"2024-10-15T14:08:13.858556Z","shell.execute_reply.started":"2024-10-15T14:08:11.378989Z","shell.execute_reply":"2024-10-15T14:08:13.857912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\ndef solve_problem(problem):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": f\"\"\"\n            Problem: {problem}\n            \n            Instruction: Write Python code to solve the problem, ensuring the result is an integer. The code should return only an integer as output.\n            Note that the intermediary calculations may be real numbers, but the final numercal answer would always be an integer.do not give 0 as answer.        \n            \nExample 1:\n  Input: Sum of all prime numbers between 50 and 100\n  Output: 1060\n  Explanation: The prime numbers between 50 and 100 are 53, 59, 61, 67, 71, 73, 79, 83, 89, 97. \n  Their sum is:\n  53 + 59 + 61 + 67 + 71 + 73 + 79 + 83 + 89 + 97 = 1060\n\n  Example 2:\n  Input: Product of all even numbers between 1 and 20, excluding multiples of 5\n  Output: 46080\n  Explanation: The even numbers between 1 and 20 are 2, 4, 6, 8, 10, 12, 14, 16, 18, 20. Excluding multiples of 5 (10 and 20), we have:\n  2 * 4 * 6 * 8 * 12 * 14 * 16 * 18 = 46080\n\n  Example 3:\n  Input: Count of Fibonacci numbers less than 1000\n  Output: 16\n  Explanation: The Fibonacci sequence is 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, 377, 610, 987. \n  There are 16 Fibonacci numbers less than 1000.\n\n  Example 4:\n  Input: Difference between the sum of the squares of all integers from 1 to 50 and the sum of all integers from 1 to 50\n  Output: 42925\n  Explanation: The sum of the squares of integers from 1 to 50 is:\n  1^2 + 2^2 + 3^2 + ... + 50^2 = 42925. \n  The sum of integers from 1 to 50 is:\n  1 + 2 + 3 + ... + 50 = 1275. \n  The difference is:\n  42925 - 1275 = 42925 \n            \"\"\"\n        },\n    ]\n    \n    # Create the prompt for the model\n    prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    \n    # Configuration for text generation\n    gen_config = {\n        \"max_new_tokens\": 1024,\n        \"do_sample\": False,\n        \"stop_strings\": [\"```output\"],  # Stop at the code output block\n        \"tokenizer\": pipe.tokenizer,\n    }\n\n    # Generate the solution using the pipeline\n    outputs = pipe(prompt, **gen_config)\n    \n    # Extract the generated text (solution)\n    text = outputs[0][\"generated_text\"]\n    \n    #print(text)\n    \n    # Attempt to extract Python code if present\n    python_code_matches = re.findall(r\"```python(.*?)```\", text, re.DOTALL)\n    \n    if python_code_matches:\n        python_code = python_code_matches[0]\n        #print(\"Extracted Python code:\")\n        #print(python_code)\n        \n        # Add validation or manual inspection before executing the code\n        try:\n            # Redirect the output to capture the result of the print statement\n            old_stdout = sys.stdout\n            new_stdout = io.StringIO()\n            sys.stdout = new_stdout\n            \n            # Execute the extracted Python code\n            exec(python_code)\n\n            # Capture the output\n            result = new_stdout.getvalue().strip()\n\n            # Reset stdout\n            sys.stdout = old_stdout\n\n            # Extract the final numeric answer from the output\n            print(f\"Extracted answer: {result}\")\n            return result\n\n        except Exception as e:\n            print(f\"Error executing code: {e}\")\n            return None\n    else:\n        print(\"No Python code found in the response.\")\n        return None\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-15T13:58:49.623539Z","iopub.execute_input":"2024-10-15T13:58:49.624181Z","iopub.status.idle":"2024-10-15T14:00:17.727192Z","shell.execute_reply.started":"2024-10-15T13:58:49.624143Z","shell.execute_reply":"2024-10-15T14:00:17.726311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef solve_problem(problem):\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": f\"\"\"\n            Problem: {problem}\n            \n            Instruction: Write Python code to solve the problem, ensuring the result is an integer. The code should return only an integer as output.\n            Note that the intermediary calculations may be real numbers, but the final numercal answer would always be an integer.do not give 0 as answer.        \n            \nExample 1:\n  Input: Sum of all prime numbers between 50 and 100\n  Output: 1060\n  Explanation: The prime numbers between 50 and 100 are 53, 59, 61, 67, 71, 73, 79, 83, 89, 97. \n  Their sum is:\n  53 + 59 + 61 + 67 + 71 + 73 + 79 + 83 + 89 + 97 = 1060\n\n  Example 2:\n  Input: Product of all even numbers between 1 and 20, excluding multiples of 5\n  Output: 46080\n  Explanation: The even numbers between 1 and 20 are 2, 4, 6, 8, 10, 12, 14, 16, 18, 20. Excluding multiples of 5 (10 and 20), we have:\n  2 * 4 * 6 * 8 * 12 * 14 * 16 * 18 = 46080\n            \"\"\"\n        },\n    ]\n    \n    # Create the prompt for the model\n    prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    \n    # Configuration for text generation\n    gen_config = {\n        \"max_new_tokens\": 1024,\n        \"do_sample\": False,\n        \"stop_strings\": [\"```output\"],  # Stop at the code output block\n        \"tokenizer\": pipe.tokenizer,\n    }\n\n    # Generate the solution using the pipeline\n    outputs = pipe(prompt, **gen_config)\n    \n    # Extract the generated text (solution)\n    text = outputs[0][\"generated_text\"]\n    \n    print(text)\n    \n    # Attempt to extract Python code if present\n    python_code_matches = re.findall(r\"```python(.*?)```\", text, re.DOTALL)\n    \n    if python_code_matches:\n        python_code = python_code_matches[0]\n        #print(\"Extracted Python code:\")\n        #print(python_code)\n        \n        # Add validation or manual inspection before executing the code\n        try:\n            # Redirect the output to capture the result of the print statement\n            old_stdout = sys.stdout\n            new_stdout = io.StringIO()\n            sys.stdout = new_stdout\n            \n            # Execute the extracted Python code\n            exec(python_code)\n\n            # Capture the output\n            result = new_stdout.getvalue().strip()\n\n            # Reset stdout\n            sys.stdout = old_stdout\n\n            # Extract the final numeric answer from the output\n            print(f\"Extracted answer: {result}\")\n            return result\n\n        except Exception as e:\n            print(f\"Error executing code: {e}\")\n            return None\n    else:\n        print(\"No Python code found in the response.\")\n        return None\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-15T14:08:25.215648Z","iopub.execute_input":"2024-10-15T14:08:25.216303Z","iopub.status.idle":"2024-10-15T14:08:25.226085Z","shell.execute_reply.started":"2024-10-15T14:08:25.216259Z","shell.execute_reply":"2024-10-15T14:08:25.225380Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['Translated_Problem'][0]","metadata":{"execution":{"iopub.status.busy":"2024-10-15T14:03:51.587905Z","iopub.execute_input":"2024-10-15T14:03:51.588674Z","iopub.status.idle":"2024-10-15T14:03:51.594318Z","shell.execute_reply.started":"2024-10-15T14:03:51.588635Z","shell.execute_reply":"2024-10-15T14:03:51.593743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"solve_problem(test_df['Translated_Problem'][0])","metadata":{"execution":{"iopub.status.busy":"2024-10-15T14:08:44.534209Z","iopub.execute_input":"2024-10-15T14:08:44.535162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Submission","metadata":{}},{"cell_type":"code","source":"import csv\nfrom tqdm import tqdm\nimport gc","metadata":{"execution":{"iopub.status.busy":"2024-10-15T14:00:17.728345Z","iopub.execute_input":"2024-10-15T14:00:17.728659Z","iopub.status.idle":"2024-10-15T14:00:17.732692Z","shell.execute_reply.started":"2024-10-15T14:00:17.728625Z","shell.execute_reply":"2024-10-15T14:00:17.731822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In DEBUG mode, infer only on 5 problems\nDEBUG = False \n# Number of candidate solutions to generate\nK = 4","metadata":{"execution":{"iopub.status.busy":"2024-10-15T14:00:17.734541Z","iopub.execute_input":"2024-10-15T14:00:17.734832Z","iopub.status.idle":"2024-10-15T14:00:20.972427Z","shell.execute_reply.started":"2024-10-15T14:00:17.734801Z","shell.execute_reply":"2024-10-15T14:00:20.971061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DEBUG:\n    test_df = test_df[:5]\n    torch.cuda.empty_cache()\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2024-10-15T13:53:38.778373Z","iopub.status.idle":"2024-10-15T13:53:38.778838Z","shell.execute_reply.started":"2024-10-15T13:53:38.778591Z","shell.execute_reply":"2024-10-15T13:53:38.778616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file = open('submission.csv', 'w', encoding='utf-8')\nwriter = csv.writer(file)\nwriter.writerow(['ID', 'Answer'])\n\nfor row in tqdm(test_df.values):\n    id = row[0]\n    translated_problem = row[2]    \n    answer = solve_problem(translated_problem)\n    print(f\"solution answer-----{answer}\")\n    \n    if DEBUG:\n        print('id: ', id)\n        print('problem: ', problem)\n        print('answer: ', answer)\n        \n    # Handling different answer types\n    if answer is None:\n        answer = 0\n    \n        \n    writer.writerow([id, answer])\n    \nfile.close()","metadata":{"execution":{"iopub.status.busy":"2024-10-15T14:00:20.973887Z","iopub.execute_input":"2024-10-15T14:00:20.974392Z","iopub.status.idle":"2024-10-15T14:03:42.853826Z","shell.execute_reply.started":"2024-10-15T14:00:20.974269Z","shell.execute_reply":"2024-10-15T14:03:42.852816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read the CSV file into a DataFrame\ndf = pd.read_csv('submission.csv')\ndf","metadata":{"execution":{"iopub.status.busy":"2024-10-15T13:53:38.782487Z","iopub.status.idle":"2024-10-15T13:53:38.782976Z","shell.execute_reply.started":"2024-10-15T13:53:38.782708Z","shell.execute_reply":"2024-10-15T13:53:38.782733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Read the CSV file into a DataFrame\ndf = pd.read_csv('submission.csv')\n\n# Function to check if a value is an integer or float and return an integer, otherwise return 0\ndef ensure_integer(value):\n    try:\n        # If it's a float, round it to the nearest integer\n        if isinstance(value, float):\n            return round(value)\n        # Try converting the value to an integer\n        return int(value)\n    except (ValueError, TypeError):\n        # If conversion fails (e.g., for strings), return 0\n        return 0\n\n# Apply the function to the entire DataFrame\ndf = df.applymap(ensure_integer)\n\n# Display the cleaned DataFrame\nprint(df)\n\n# Optionally, save the cleaned DataFrame back to a new CSV file\ndf.to_csv('cleaned_file.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-15T13:53:38.784196Z","iopub.status.idle":"2024-10-15T13:53:38.784660Z","shell.execute_reply.started":"2024-10-15T13:53:38.784421Z","shell.execute_reply":"2024-10-15T13:53:38.784446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Apply the model to each problem in the DataFrame\ntest_df['Solution'] = test_df['Translated_Problem'].apply(solve_problem)\n\n# Display the DataFrame with the solutions\nprint(test_df[['Translated_Problem', 'Solution']])","metadata":{"execution":{"iopub.status.busy":"2024-10-15T13:53:38.786016Z","iopub.status.idle":"2024-10-15T13:53:38.786478Z","shell.execute_reply.started":"2024-10-15T13:53:38.786241Z","shell.execute_reply":"2024-10-15T13:53:38.786265Z"},"trusted":true},"execution_count":null,"outputs":[]}]}